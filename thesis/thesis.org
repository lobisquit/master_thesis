#+STARTUP: indent

#+PROPERTY: header-args :cache yes

#+OPTIONS: toc:nil title:nil

#+LATEX_CLASS: dissertate
#+LATEX_COMPILER: xelatex

#+LaTeX_HEADER: \setmainfont{Charis SIL}

#+LATEX_HEADER: \usepackage{geometry}
#+LATEX_HEADER: \usepackage{etoolbox}
#+LATEX_HEADER: \usepackage{multirow}
#+LATEX_HEADER: \usepackage{xspace}
#+LaTeX_HEADER: \usepackage{booktabs}

#+LaTeX_HEADER: \allowdisplaybreaks
#+LaTeX_HEADER: \def\equationautorefname#1#2\null{(#2\null)}
#+LaTeX_HEADER: \def\algorithmautorefname#1#2\null{Algorithm~#2\null}
#+LaTeX_HEADER: \def\figureautorefname#1#2\null{Fig.~#2\null}
#+LATEX_HEADER: \providetoggle{images_titlepage}
#+LATEX_HEADER: \settoggle{images_titlepage}{true}

#+LaTeX_HEADER: \setlength{\parindent}{0cm}
#+LATEX_HEADER: \setlength{\parskip}{0.25em}

#+LATEX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \newenvironment{bigalgorithm}
#+LATEX_HEADER:   {% \begin{bigalgorithm}
#+LATEX_HEADER:    \begin{center}
#+LATEX_HEADER:      \refstepcounter{algorithm}% New algorithm
#+LATEX_HEADER:      \hrule height.8pt depth0pt \kern2pt% \@fs@pre for \@fs@ruled
#+LATEX_HEADER:      \renewcommand{\caption}[2][\relax]{% Make a new \caption
#+LATEX_HEADER:        {\raggedright\textbf{\ALG@name~\thealgorithm} ##2\par}%
#+LATEX_HEADER:        \ifx\relax##1\relax % #1 is \relax
#+LATEX_HEADER:          \addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##2}%
#+LATEX_HEADER:        \else % #1 is not \relax
#+LATEX_HEADER:          \addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##1}%
#+LATEX_HEADER:        \fi
#+LATEX_HEADER:        \kern2pt\hrule\kern2pt
#+LATEX_HEADER:      }
#+LATEX_HEADER:   }{% \end{bigalgorithm}
#+LATEX_HEADER:      \kern4pt\hrule\relax% \@fs@post for \@fs@ruled
#+LATEX_HEADER:    \end{center}
#+LATEX_HEADER:   }
#+LATEX_HEADER: \makeatother

#+LATEX_HEADER: \newcommand{\etal}{\mbox{\emph{et al.}}\xspace}

#+LATEX_HEADER_EXTRA: \newacronym{pop}{PoP}{Point of Presence}
#+LATEX_HEADER_EXTRA: \newacronym{dslam}{DSLAM}{Digital Subscriber Line Access Multiplexer}
#+latex_header_extra: \newacronym{qos}{QoS}{Quality of Service}
#+latex_header_extra: \newacronym{nic}{NIC}{Network Interface Card}
#+latex_header_extra: \newacronym{qoe}{QoE}{Quality of Experience}
#+latex_header_extra: \newacronym{cbr}{CBR}{Constant Bitrate}
#+latex_header_extra: \newacronym{forces}{ForCES}{Forwarding and Control Element Separation}
#+latex_header_extra: \newacronym{ilp}{ILP}{Integer Linear Programming}
#+latex_header_extra: \newacronym{sdn}{SDN}{Software Defined Network}
#+latex_header_extra: \newacronym{isp}{ISP}{Internet Service Provider}
#+latex_header_extra: \newacronym{hd}{HD}{High Definition}
#+latex_header_extra: \newacronym{md}{MD}{Medium Definition}
#+latex_header_extra: \newacronym{ld}{LD}{Low Definition}
#+latex_header_extra: \newacronym{pon}{PON}{Passive Optical Network}
#+latex_header_extra: \newacronym{tcp}{TCP}{Transmission Control Protocol}
#+latex_header_extra: \newacronym{mos}{MOS}{Mean Opinion Score}
#+latex_header_extra: \newacronym{nos}{NOS}{Network Operating System}
#+latex_header_extra: \newacronym{ftth}{FTTH}{Fiber to the home}

* Utility code                                                       :ignore:
** Latex title page                                                 :ignore:
#+BEGIN_EXPORT latex
\newgeometry{top=1in, bottom=1in, inner=1in, outer=1in}
\begin{titlepage}
  {\Large University of Padova}
  \vspace{4mm}

  {\Large Department of Information Engineering}

  \begin{center}
    \vspace{8mm}
    {\Large \textsl{Master degree in Telecommunication Engineering}} \\
    \vspace{8mm}
    {\scshape\LARGE Traffic flow optimization \\[0.3em] for urban xDSL based access networks }

    \iftoggle{images_titlepage}{
      \vspace{8mm}
      \begin{figure}[h]
        \centering
        \includegraphics[height=5cm]{../figures/logo_unipd.pdf}
        \vspace{5mm} \\
        \includegraphics[height=2cm]{../figures/logo_rwth.pdf}
      \end{figure}
    }

  \end{center}

  \vfill

  \renewcommand{\arraystretch}{2.5}
  \begin{tabular}{lr}
    \large \textsl{Author}               & \hspace{5mm} \large Enrico Lovisotto      \\
    \large \textsl{Internal supervisor}  & \hspace{5mm} \large Prof. Andrea Zanella  \\
    \large \textsl{External supervisors} & \hspace{5mm} \large Prof. Petri Mähönen  \\
                                         & \hspace{5mm} \large Dr. Ljiljana Simić   \\
  \end{tabular}
  \vspace{6mm}
  \begin{flushright}
    \large April 8, 2019 \\[0.5em]
    \large Academic year 2018-2019
  \end{flushright}
\end{titlepage}

\restoregeometry
#+END_EXPORT

** PlantUML common style                                            :noexport:
#+BEGIN_COMMENT
PlantUML skin, reusable for all diagrams
#+END_COMMENT

#+NAME: plantuml_skin
#+BEGIN_SRC plantuml :exports none
  skinparam shadowing false
  skinparam padding 1
  skinparam BoxPadding 1

  'skinparam DefaultFontName Charter
  skinparam DefaultFontName Fira Sans

  skinparam defaultTextAlignment center

  skinparam SequenceDelayFontSize 15

  skinparam Note {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Node {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Cloud {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Database {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Actor {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Activity {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam activityDiamond {
  BackgroundColor white
  BorderColor black
  FontColor       black
  }

  skinparam ArrowColor black

  skinparam State {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam SequenceParticipant {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Interface {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam SequenceLifeLine {
  BorderColor black
  BackgroundColor black
  }

  skinparam Queue {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Usecase {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }
#+END_SRC

** Download university logos                                        :noexport:
#+BEGIN_COMMENT
Download all needed files for titlepage and convert them.
LaTeX support for svg files sucks.
#+END_COMMENT

#+BEGIN_SRC bash :exports none :results none
  wget https://upload.wikimedia.org/wikipedia/it/5/53/Logo_Universit%C3%A0_Padova.svg \
       -O ../figures/logo_unipd.svg

  inkscape ../figures/logo_unipd.svg --export-pdf=../figures/logo_unipd.pdf

  wget https://upload.wikimedia.org/wikipedia/commons/1/11/RWTH_Logo.svg \
       -O ../figures/logo_rwth.svg

  inkscape ../figures/logo_rwth.svg --export-pdf=../figures/logo_rwth.pdf
#+END_SRC

** Asymptote preamble                                               :noexport:
#+NAME: asymptote_preamble
#+BEGIN_SRC asymptote :exports none
  settings.outformat="pdf";

  texpreamble("\usepackage[sfdefault]{Fira Sans}");
  texpreamble("\usepackage{newtxsf}");

  // texpreamble("\usepackage{charter}");
  // texpreamble("\usepackage[charter]{mathdesign}");
#+END_SRC

** Python preamble                                                  :noexport:
#+NAME: python_preamble
#+BEGIN_SRC python :exports none
  import matplotlib.pyplot as plt

  from matplotlib import rcParams

  font_spec = {
      'font.family':'sans-serif',
      'font.sans-serif':['Fira Sans'],
      'font.weight': 'regular',
      'axes.titleweight': 'regular'
  }
  rcParams.update(font_spec)
#+END_SRC

** R preamble                                                       :noexport:
#+NAME: R_preamble
#+BEGIN_SRC R :exports none
  .libPaths("/opt/R/x86_64-pc-linux-gnu-library")

  library(reshape2)
  library(ggplot2)
  library(scales)
  library(extrafont)
  library(gridExtra)
  library(latex2exp)
  library(readr)
  library(dplyr)
  library(data.table)
  library(purrr)
  library(viridis)

  loadfonts()

  my_theme <- theme_bw() +
    theme(
      text = element_text(family = "Fira Sans")
    )
#+END_SRC

* Latex lists                                                        :ignore:
#+BEGIN_EXPORT latex
\frontispiece
\sommario
\tableofcontents
\phantomsection
\clearpage

% figure listing - required if you have any figures
\addcontentsline{toc}{chapter}{List of figures}
\listoffigures
\phantomsection
\cleardoublepage

% table listing - required if you have any tables
\addcontentsline{toc}{chapter}{List of tables}
\listoftables
\phantomsection
\cleardoublepage

\setcounter{page}{1}
\pagenumbering{arabic}
#+END_EXPORT

* Introduction
:PROPERTIES:
:CUSTOM_ID: introduction
:END:

#+BEGIN_SRC org :exports none
  + background: what are we talking about?
    - SDN => self-optimizing networks
    - flow balancing
    - routing adaptation

  + what they do now?
    - summary of state of the art, /basically/

  + shortcomings in current knowledge / solutions
    - limits of SDN over traditional networks: lack of negative results
    - use of abstract topologies ~> this one is obtained through optimization process

  + what are we gonna prove?
    - 99% if the networks are very simple, meant to be more flow aggregators and less clever routers
    - SDN are not inherently good: /probably/ traditional solutions are good in 99% of the networks
    - SDN are relevant when the complexity of the network grows
#+END_SRC

# SDN

Since the creation of the public Internet, the configuration of the network
layer of the protocol stack has been static. Each route has either been
discovered by the device itself or set by the hand of the administrator: in both
cases no tools were available to quickly modify the behaviour according to
changes in traffic demand or network structure.

In last years, this inflexible paradigm was questioned, as the complexity and
sheer amount of data exchanged in the Internet grew dramatically, as shown in
autoref:fig:internet_user_growth. Moreover, traffic is not yet expected to
stabilize, according to \textsc{cisco} predictions, plotted in
autoref:fig:internet_traffic_growth cite:CiscoVisualNetworking.

#+NAME: fig:internet_user_growth
#+BEGIN_SRC asymptote :file ../figures/internet_user_growth.pdf :noweb yes
  <<asymptote_preamble>>

  import graph;

  size(8cm, 8cm, IgnoreAspect);

  int[] years = { 2005,
                  2006,
                  2007,
                  2008,
                  2009,
                  2010,
                  2011,
                  2012,
                  2013,
                  2014,
                  2015,
                  2016,
                  2017,
                  2018 };

  real xmin = 0.5;
  real xmax = 8;

  real[] people = { 1.018, // 2005
                    1.093, // 2006
                    1.319, // 2007
                    1.574, // 2008
                    1.802, // 2009
                    1.971, // 2010
                    2.267, // 2011
                    2.497, // 2012
                    2.802, // 2013
                    3.079, // 2014
                    3.366, // 2015
                    3.696, // 2016
                    4.156, // 2017
                    4.502, // 2018
  };

  real ymin = 0.5;
  real ymax = 8;

  draw(graph(x=years, y=people, join=operator ..), red + linewidth(1.1pt));

  xaxis(axis=YEquals(0.5),
        xmin=years[0] - 1,
        xmax=years[years.length - 1] + 2,
        ticks=LeftTicks(Label(fontsize(8)),
                        beginlabel=false,
                        Step=2,
                        step=1,
                        modify=OmitTickInterval(2019, inf)),
        arrow=Arrow());

  yaxis(axis=Left,
        ymin=0.5,
        ymax=people[people.length - 1] + 0.5,
        ticks=RightTicks(format=Label("$%.4g \times 10^{\,9}$", fontsize(8)),
                         modify=OmitTickInterval(4.6, inf),
                         extend=false,
                         beginlabel=true),
        arrow=Arrow);

  label(L="Internet users progression",
        position=point(N),
        align=shift(0, 1) * N,
        p=fontsize(10));
#+END_SRC

#+CAPTION: Number of Internet users has steadily increased for the past fifteen years.
#+ATTR_LATEX: :width 8cm
#+LABEL: fig:internet_user_growth
#+RESULTS[dd898a6e8f1c1a392105d8f4ee3540a56eeb2a81]: fig:internet_user_growth
[[file:../figures/internet_user_growth.pdf]]

In order to prevent the ``ossification of the Internet'' cite:Hakiri2014 and
adapt to these new scenarios, it is in fact essential to separate the
\emph{data plane}, the actual physical devices forwarding packets, from the
\emph{control plane}, responsible for deciding routes.

The latter operations are supervised by a logically centralized
\emph{controller}, whose task is to orchestrate involved routers and switches
based on current and forecast network status. This moves the routing logic from
the single component to a fully programmable core entity.

In case of congestion of a particular link, for example, a data flow can be
diverted to another path, possibly increasing [[ac:qos][QoS]] for all users. This can be
very interesting in cable networks, where gridlock is indeed the main issue for
administrators.

#+NAME: fig:internet_traffic_growth
#+BEGIN_SRC asymptote :file ../figures/internet_traffic_growth.pdf :noweb yes
  <<asymptote_preamble>>

  import graph;

  size(8cm, 8cm, IgnoreAspect);

  int[] years = { 2017,
                  2018,
                  2019,
                  2020,
                  2021,
                  2022 };

  real xmin = 0.5;
  real xmax = 8;

  real[] traffic = { 122, // 2017
                     156, // 2018
                     201, // 2019
                     254, // 2020
                     319, // 2021
                     396, // 2022
  };

  real ymin = 0.5;
  real ymax = 8;

  draw(graph(x=years, y=traffic, join=operator ..), green + linewidth(1.1pt));

  xaxis(axis=YEquals(0.5),
        xmin=years[0] - 1,
        xmax=years[years.length - 1] + 2,
        ticks=LeftTicks(Label(fontsize(8)),
                        beginlabel=false,
                        Step=2,
                        step=1,
                        modify=OmitTickInterval(years[years.length - 1] + 1, inf)),
        arrow=Arrow());

  yaxis(axis=Left,
        ymin=0.5,
        ymax=traffic[traffic.length - 1] + 100,
        ticks=RightTicks(format=Label("$%.4g$EB/month", fontsize(8)),
                         modify=OmitTickInterval(401, inf),
                         extend=false,
                         beginlabel=true),
        arrow=Arrow);

  label(L="Internet traffic projection",
        position= point(N),
        align=shift(0, 1) * N,
        p=fontsize(10));
#+END_SRC

#+CAPTION: Internet traffic is expected to explode in the next years.
#+ATTR_LATEX: :width 8cm
#+LABEL: fig:internet_traffic_growth
#+RESULTS[d0fb950dc24a9d2ca530cdbce49a22ab3c6ccf75]: fig:internet_traffic_growth
[[file:../figures/internet_traffic_growth.pdf]]

Given the demand for connectivity and bandwidth, [[acp:sdn][SDN]] are now a ground-breaking
approach to further improve the performance using unconventional approaches. Not
only flow control, but also user mobility prediction could be exploited by the
programmable controller logic.

However, as every tool, its makings have to be coupled with a robust knowledge
on its limits. This information is therefore crucial to make the most out of
[[ac:sdn][SDN]] as, from a methodological point of view, alleged once-and-for-all
solutions often fall short when context changes from the expected one: .

As mentioned before, [[acp:sdn][SDNs]] are indeed popular nowadays when dealing with very
high bandwidth link management in scenarios that are complex because of either
topology or applications demand cite:Singh2015.

#+CAPTION: Data flow of users (squares) are tuned and managed by the SDN controller via the routers (circles).
#+ATTR_LATEX: :width 8cm
#+LABEL: fig:network_planes
[[file:../figures/network_planes.pdf]]

In this thesis we aim then to understand what happens at the other side of the
spectrum, i.e. when dealing with static and simple access networks. At the
moment no study has been devoted to understand and quantify how much a
controller can improve [[ac:qos][QoS]] in these simple, but very common, settings.

We specifically focus on the access network of Aachen, historical city in the
German state of North Rein-Westphalia. As the actual schematics are not
available to the general public, our network topology is inferred by residential
buildings and population distribution across the area, solving an optimization
problem.

After this design step we simulate the normal operation of the infrastructure,
where a certain number of clients requires traffic for their applications. In
this setting we try to assess whether an [[ac:sdn][SDN]] inspired approach can effectively
increment [[ac:qoe][QoE]] for the users.

While state-of-the-art utility functions are employed as service-specific
quality measures, a comprehensive assessment is performed using a
game-theoretical framework, known as \emph{Nash arbitration scheme}. Obtained
operation point is the only one that guarantees a \emph{fair} allocation of
resources among users and it is proven to maximize the product of the utilities.

More specifically then, our goal is to compare traditional network management
technique to this novel approach in a real-world scenario.

\bigskip

This thesis is structured as follows.

First, an overview of past works related to this thesis scope is provided in
autoref:state_of_art.

Then, autoref:methodology introduces the theoretical instruments employed in
this analysis. In autoref:methodology-geographical_analysis, we will show how
relevant information from Aachen building and road map can be extracted in order
to design a proper access network based
on city topology and population density, in autoref:methodology-network_design.
autoref:methodology-network_optimization will detail how this infrastructure can
be tuned for maximize user perceived [[ac:qoe][QoE]].

After applying these procedures to our case of study, final results are
collected and commented in autoref:results, split again into geographical
analysis, network design and optimization, in
autoref:results-geographical_analysis, autoref:results-network_design and
autoref:results-network_optimization respectively.

Final remarks and considerations are eventually discussed in autoref:conclusion.

* State of the art
:PROPERTIES:
:CUSTOM_ID: state_of_art
:END:

#+BEGIN_SRC org :exports none
  One subsection for each of the macro-areas

  - access networks design

  - SDN!
    - applications and general concept

  - flow control
    - game between users and ISP -> game theory
    - fairness in network management -> Nash arbitration scheme
    - water filling approaches for resource allocation
#+END_SRC

As mentioned in the introduction, the first step of this thesis is the
estimation of the Aachen city network, given publicly available information on
city topology and population density.

\bigbreak

Once extracted the relevant feature of the geographical area, the designing of such
a network is a matter of connecting all terminals to a central unit, aggregating
user traffic to a single end-point.

# Steiner tree = most general problem

This is known in literature as the Steiner tree problem. On a graph $G=(V,\,E)$
a set $T \subset V$ of nodes have to be reached from a root $r \in V$: the goal
is to select the subset of edges in $E$ that activates those links at minimum
cost.

This problem was proven to be NP-hard and has been extensively studied and
solved both with exact and approximated solutions
cite:Voss1992,Rehfeldt2015,Koch1998,Leitner2014.

A reference formulation of it is given in autoref:eq:steiner_tree_reference,
where active edges $e \in E$ are marked by a binary variable $x_e$ and a cost
$c_e$. Function $\delta^{+}(\mathord{\cdot})$ and $\delta^{-}(\mathord{\cdot})$,
instead, give the edges entering or exiting their argument, respectively.

\begin{equation}
  \begin{split}
    \max ~ & \sum_{e \in E} x_e c_e\\
    \text{given} ~
    & \sum_{e \in \delta^-(j)} x_e ~ \begin{dcases}
      = 1 & j \in T \\
      = 0 & j = r \\
      \le 1 & j \in V \smallsetminus (T \cup \{r\})
    \end{dcases} \\
    & \sum_{e \in \delta^+(S)} x_e \ge \sum_{e \in \delta^-(t)} x_e \quad\forall S \subset V,~ \text{with } r \in S,~ t \in V \smallsetminus S \\
    & x_e \in \{0,\,1\} ~ \forall e \in E
  \end{split}
  \label{eq:steiner_tree_reference}
\end{equation}

\smallbreak

# Andrews

In our case, though, reachability is not sufficient to declare a user connected,
as its traffic has to be supported by all links in the path to the root as well.

Accounting for this factor, Steiner tree was extended adding flow conditions for
bandwidth and link types of different capacity by Andrews \etal cite:Andrews1998.
Moreover, here fixed edge activation cost $c_e$ becomes proportional to the
bandwidth used and a fixed cost for the activation is considered, resulting in
the scenario of autoref:fig:andrews_model.

#+LABEL: fig:andrews_model
#+ATTR_LATEX: :width 7.2cm
#+CAPTION: Each intermediate node in the tree merges the flows coming from the leaves and splits the return ones cite:Andrews1998.
[[file:../figures/andrews_model.pdf]]

A mathematical formulation describing the optimal solution is given in their
paper, and it is coupled with an approximated solver algorithm obtained via
linear programming relaxations, whose penalty with respect to the optimum is
bounded.

This approach, though, does not take into account the technological constraints,
such as a maximum number of ports in traffic aggregators and limits in cable
length.

\smallbreak

This last point is addressed in Mitcsenkov \etal cite:Mitcsenkov2011, where they consider for the
same setting various technologies, such as [[acp:pon][PON]], Active Ethernet and VDSL, each
one with its own constraints.

Moreover, the access network is built not from an abstract model, but from a set
of reference topographic scenarios, such as suburban, town or city, in
increasing population density.

Here the mathematical problem, with exact solution but infeasible computation,
is coupled with heuristic algorithms tailored to the given physical layer
assumptions. Both are run on reference maps, ranging from 0.5km^2 to 4.7km^2 of
surface and from 400 to 20.000 number of users. These trials show the viability
of the approach, as the approximated solution is within 10% to 15% the
theoretical bound provided via an [[ac:ilp][ILP]] solver, while being still fast to compute.

\smallbreak

These studies are useful insights on how to design a practical access network.
Proposed tools are not enough, though, as either the conditions or the scale of
our reference scenario are out of reach for them: as an example, Aachen has an
estimated number of 40.000 subscribers spread across 160.85km^2, both unfeasible
for state-of-the-art algorithms.

Therefore, new approaches will be devised in this thesis, in order to properly
solve the problem and possibly get the approximation closer to the theoretical
bounds.

\bigbreak

# SDN: general concept + small history

Once built, the resulting network has to be properly managed in order to offer a
decent [[ac:qos][QoS]] to end users, for example adopting congestion avoidance and load
balancing strategies. However, enforcing these policies in traditional IP
networks is a daunting task for administrators cite:Benson2009.

This is mainly caused by the need to use vendor-specific interfaces to specify
switching units behavior, most notably setting and updating routing tables and
requesting network status report. This inhibits a global orchestration across
the whole infrastructure, as specific quirks and capabilities of each device
have to be carefully abstracted. This operation needs to be repeated every time
one of the protocol changes or a new kind of items is added. Therefore,
automatic reconfiguration upon failure or dramatic load change is virtually
non-existent in such systems.

Moreover, IP networks are now mostly \emph{vertically integrated}, meaning that
policy specification and implementation, known as \emph{control plane} and
\emph{data plane} respectively, are allocated in the switching units. This
reduces system flexibility and resilience as, for example, a simple change of
routing protocol needs careful planning and a lot of man hours to be put in
practice.

[[ac:sdn][SDN]] is an emerging paradigm that tries to seize the problem by the roots,
finally separating data and control plane. While the former remains in the
devices, the latter logic is implemented in controller. Either as a physical
device itself or a distributed entity, it can be programmed to put in practice
high-level policies without the administrator to manually delve into all the
details.

In order for the controller to operate and manage all diverse switching units, a
proper vendor-agnostic communication interface has to be designed. The first
widespread example of such a protocol was OpenFlow, proposed in 2008 by the
Stanford computer science department cite:Mckeown2008.

Each OpenFlow device has multiple tables to match incoming packets to a
programmable set of rules: these allow modification, forwarding and dropping of
data, along with sending reports of anomalies and statistics to the controller.
According to installed policies, each network unit can then act as a switch, a
router, a firewall and this behaviour can be easily modified by the
administrator.

The new possibilities and the practical viability of the protocol started to
attract not only academical contributions, for instance NOX [[ac:nos][NOS]] cite:Gude2008,
but also industrial interested from many preeminent actors. Google
cite:Jain2013, WMware cite:WMWareNSX and many operators around the world
cite:OpenDaylight started to experiment and deploy software-defined solutions in
their infrastructure, reporting performance and flexibility gains.

\bigbreak

# flow control

Given our reference scenario, the levers offered by an [[ac:sdn][SDN]] approach are limited.
As mentioned before, our reference topology is a rigid and hierarchical tree:
while this minimizes infrastructure cost, no routing is possible in this
context.

The only tool left on the table is then \emph{flow control}, which is the
ability to give or revoke priority from stream of packets. Traditionally this
technique has been employed for congestion avoidance, primary example being
distributed [[ac:tcp][TCP]] strategies to match the bitrate with the actual link capacity cite:Allman2009.
Nowadays, it is becoming necessary in order to assign users the
proper amount resources their application requires. For instance, video
streaming shows a different profile than traditional web browsing and this
factor needs to be taken into account when administrating the network.

\smallbreak

In order to perform a decent and user-tailored resource distribution, the link
between actual connection metrics and user perceived quality of the service is
needed.

Many research groups estimate [[ac:qoe][QoE]] under a wide spectrum of network conditions
using the so-called [[ac:mos][MOS]], the average subjective evaluation among a group of
candidates. Georgopoulos \etal, Laghari \etal focus on the actual measurement
and try to fit what found with a shifted power function of the bandwidth
cite:Georgopoulos2013,Laghari2012. Instead, Reichl \etal go for a different
approach, as they \emph{a-priori} suppose [[ac:qoe][QoE]] to be a logarithmic function of available capacity: this
hypothesis is taken in analogy to the Weber-Fechner Law cite:Reichl2011.

This law, formulated by Gustav Theodor Fechner and its student Ernst Heinrich Weber, is a key principle in
psycho-physics that connects the magnitude of a \emph{stimulus} to its perceived
intensity.

\begin{align}
	k = \frac{\mathrm{d}S}{S} \label{eq:weber} \\
	\mathrm{d} p = k \frac{\mathrm{d} S}{S} \implies p = k \, \log \frac{S}{S_0} \label{eq:fechner}
\end{align}
where $p$ is the extent of the perception given by the external stimulus $S$.
$k$ and $S_0$ are instead constants and depend on the specific physical quantities considered.

Former equation autoref:eq:weber, known as \emph{Weber's contrast},
This was supposed after performing an experiment, consisting in a man judging
the weight of an object: it was observed that constant increments in the weight
were more noticeable when the object itself was light.
Thus it was concluded that the differential stimulus is inversely proportional to the stimulus itself.

Latter equation autoref:eq:fechner, tries to move forward this preliminary result as
general increments are allowed. The final relation between stimulus and perception is therefore logarithmic.

These investigations give us analytical tools to effectively simulate and
reproduce satisfaction for each user.

\smallbreak

Once individual metrics are computed, it is necessary to aggregate all these [[acp:qoe][QoE]]
into a global score, in order to choose the best among all possible network
configurations.

A game theoretical framework is proposed in literature in order to tackle this
problem. When the network is operational, in fact, there is an implicit
competition between each user wanting to maximize its own \emph{utility} at the
expense of others bandwidth. The main task of the administrator is then to guide
individual demands to a stable and \emph{fair} operation point.

``Fairness'' is, from a mathematical point of view, an elusive concept, but it
can be seen here as a condition where all users enjoy the service without being
overly penalized.

Pareto-optimal strategies are suggested by Douligeris \etal in order to capture
this requirements, as no one can increment its own utility without worsening the
experience of at least one of its fellows cite:Douligeris1987. No criterion is
however provided in order to choose among the possibly infinite number of these
solutions.

Mazumdar \etal eventually propose the so-called \emph{Nash arbitration scheme},
a stable operation point of the cooperative game played among users, located in
throughput space cite:Mazumdar1991. Such point is proved to exist and be the
only one satisfying symmetry, independence of irrelevant alternatives and Pareto
optimality. Moreover, they show that this strategy maximizes the product of
individual user utilities, giving a straightforward way to compute it in
practice.

It is important to differentiate between Nash arbitration scheme from the
popular Nash equilibrium, as the former arises from a \emph{cooperative} game,
while the latter from a \emph{competitive} one. Such equilibria are situations
where no user can increment its own utility if others behaviour stays the same
cite:Tadelis2013. These points are typically Pareto sub-optimal and therefore not
relevant for our purposes.

An example of this concept is the \emph{prisoner's dilemma}, a non-cooperative
game played between two actors $A$ and $B$. These two individuals are suspected
of a crime, but the prosecutor lacks evidence for this, while he has for some
minor charges. Both of the criminals, who have no way of communicating to each
other, can either confess the main offence or stay silent.

\begin{table}[h]
  \renewcommand*{\arraystretch}{1.5}
  \centering
  \begin{tabular}{c|cc}
    & A confesses & A stays silent\\
    \hline
    B confesses & -2, -2 & 0, -3\\
    B stays silent & -3, 0 & -1, -1\\
  \end{tabular}
  \caption{Each couple of strategies leads to two utility scores (years in prison), the first for B and the second for A.}
  \label{tab:prisoners_dilemma}
\end{table}

Judging from autoref:tab:prisoners_dilemma, the best course of action, meaning
the Pareto optimal strategy, is for the two of them to stay silent. This point,
however, is not a Nash equilibrium, because each one has incentive to betray the
other and spend no time in prison.

This toy example shows how Nash equilibria, originating from competitive games,
are often not optimal with respect to the global utility. In our context, then,
the operator has to enforce a fruitful coordination, the Nash arbitration
scheme, among players carefully tuning their packet flows.

* Methodology
:PROPERTIES:
:CUSTOM_ID: methodology
:END:

** Geographical analysis
:PROPERTIES:
:CUSTOM_ID: methodology-geographical_analysis
:END:

#+BEGIN_SRC org :exports none
  OpenStreetMap ~> roads + buildings graph: only methodological consideration

  + cutting NRW maps with Aachen border
  + selecting roads & buildings type
  + ~s2g~ to obtain the graph ~> cite stuff using this approach
    - road polygons to edges
    - intersections as nodes
  + adding building to the graph
    - splitting roads
    - population estimated based on district population, building area
#+END_SRC

The city of Aachen is located in the north-west of Germany, in state of North
Rhine-Westphalia. Its district has a surface of 160.85km² and a population of
244,951 citizens.

Although medium sized, the city is an important telecommunication node between
Germany and the neighbour countries of Belgium and Netherlands. The LambdaNet
backbone, owned by /euNetworks Managed Services GmbH/, crosses in fact the city
and provides direct connection to public Internet. Its map, built by ``The
Internet Topology Zoo'' project cite:topology_zoo, has been plotted in
autoref:fig:lambdanet.

In this thesis we will then suppose that the access network connects all Aachen
buildings to this main backbone via a single [[ac:pop][PoP]], located in the industrial
district of the city.

Unfortunately, schematics for such network are not publicly available, so we
have to perform what it is called an /educated guess/, meaning a good estimation
based on available information.

The evaluation will be performed using OpenStreetMap cite:OpenStreetMap in
conjunction with the /Open Data Portal/ of the city of Aachen: [fn:1] the former
provides buildings and roads positions, while the latter describes how
population is distributed across the city districts.

[fn:1] Please refer to http://daten.aachen.de for further information and licensing.


All this information can be visualized in the map of
[[autoref:fig:aachen_city_map]], in the autoref:results-geographical_analysis.

\bigbreak

Due to the level of detail of these datasets, two assumptions are needed to
proceed and extract a reasonable diagram for the access city network.

First, we suppose cables to be put along streets and not to cross (even public)
terrains. This is common practice, since roadworks are usually exploited to
perform maintenance and build new parts of the communication network.

Second, we consider the population of a given area to be uniformly distributed
across a fraction of its buildings, so-called /residential/ ones, randomly
picked among all the constructions. \\
We have to take this strong hypothesis because the OpenStreetMap dataset lacks
information about the building use and height in most entries.

These two points can be accepted in this work as the end goal is to study how
the access network of a city like Aachen behaves, not to replicate it in perfect
detail.

\bigskip

#+LABEL: fig:lambdanet
#+ATTR_LATEX: :width 10cm
#+CAPTION: LambdaNet is a national backbone that serves all major German cities and connects the country to the rest of Europe.
[[file:../figures/german_backbone.pdf]]

** Network design
:PROPERTIES:
:CUSTOM_ID: methodology-network_design
:END:

#+BEGIN_SRC org :exports none
  Using ILP to build the network

  - network requirements
    + ISP recommendations
    + best practices (CISCO, ...)
  - actual solution we are trying to find
    + optimal DSLAM positioning
    + optimal + heuristic check for routers and mainframe positions (restrict root nodes?)
  - why ILP? how does it work? (brief)
  - problem definition
    + idea for the model: Steiner tree + other constraints (cite requirements)
    + actual equations
  - problem complexity: number of variables, constraints (in theory)
#+END_SRC

This information is then condensed in an abstract graph $G=(V, \,E)$, with
streets as edges and road crossings as vertices. The former were given
corresponding lane length, while the latter were assigned the supposed number of
people living in the surrounding area.

More specifically, each node $i \in V$ is assigned a number of users $u_i$ to
serve and, since that they represent a physical line, edges in $E$ are given a
length value $l_e$: both these parameters will be used later to evaluate the
access network cost.

In this chapter we will exploit this information to find the optimal network
configuration, given some assumptions and requirements derived from best
practices in access network design cite:CiscoWAN.

*** Topology considerations
As depicted in autoref:fig:network_tree we suppose our access network to be made
of layer-2 type switches and to be logically shaped as a tree. This is indeed
common practice in such access networks, where more complex and elaborate
topologies are too expensive and offer no substantial benefit cite:CiscoWAN.

In this configuration the path from users to the provider mainframe is fixed and
must cross two kinds of intermediate nodes, a [[acp:dslam][DSLAM]] and a router.

From a technological point of view the network is considered to be relatively
modern, since the infrastructure has been renewed on the past years in
conjuction with works on main city roads.

That is the reason why we suppose all main links to be fiber optic running
state-of-the-art VDSL/VDSL2. The minor fraction of legacy ADSL and copper-cable
users can be well approximated as VDSL connections at the same distance, in
terms of bandwidth and other network metrics.

In order to guarantee a suitable [[ac:qos][QoS]], all connected network components have to
be close enough to each other: this is taken into account though a maximum
distance parameter $d_M$.

Finally, each switch is allowed to serve a limited number $n_M$ of lower level
nodes, given by the number of physical ports of the device.

#+BEGIN_SRC plantuml :file ../figures/network_tree.eps :noweb yes
  <<plantuml_skin>>
  skinparam nodesep 10

  queue Backbone as b

  rectangle Mainframe as m #ff9b9b

  rectangle Router as r1 #ffda9b
  rectangle Router as r2 #ffda9b
  rectangle Router as r3 #ffda9b

  rectangle DSLAM as d1 #f6ff9b
  rectangle DSLAM as d2 #f6ff9b
  rectangle DSLAM as d3 #f6ff9b
  rectangle DSLAM as d4 #f6ff9b
  rectangle DSLAM as d5 #f6ff9b
  rectangle DSLAM as d6 #f6ff9b

  interface " " as c1
  interface " " as c2
  interface " " as c3
  interface " " as c4
  interface " " as c5
  interface " " as c6
  interface " " as c7
  interface " " as c8
  interface " " as c9
  interface " " as c10
  interface " " as c11
  interface " " as c12
  interface " " as c13
  interface " " as c14
  interface " " as c15
  interface " " as c16
  interface " " as c17
  interface " " as c18

  b -- m

  m -- r1
  m -- r2
  m -- r3

  r1 -- d1
  r1 -- d2
  r2 -- d3
  r2 -- d4
  r3 -- d5
  r3 -- d6

  d1 -- c1
  d1 -- c2
  d1 -- c3
  d2 -- c4
  d2 -- c5
  d2 -- c6
  d3 -- c7
  d3 -- c8
  d3 -- c9
  d4 -- c10
  d4 -- c11
  d4 -- c12
  d5 -- c13
  d5 -- c14
  d5 -- c15
  d6 -- c16
  d6 -- c17
  d6 -- c18

  r1 -[hidden] r2
  r2 -[hidden] r3

  d1 -[hidden] d2
  d2 -[hidden] d3
  d3 -[hidden] d4
  d4 -[hidden] d5
  d5 -[hidden] d6

  c1 -[hidden] c2
  c2 -[hidden] c3
  c3 -[hidden] c4
  c4 -[hidden] c5
  c5 -[hidden] c6
  c6 -[hidden] c7
  c7 -[hidden] c8
  c8 -[hidden] c9
  c9 -[hidden] c10
  c10 -[hidden] c11
  c11 -[hidden] c12
  c12 -[hidden] c13
  c13 -[hidden] c14
  c14 -[hidden] c15
  c15 -[hidden] c16
  c16 -[hidden] c17
  c17 -[hidden] c18
#+END_SRC

#+LABEL: fig:network_tree
#+CAPTION: A layered tree access network connects users (circles) to the Internet backbone
#+ATTR_LATEX: :height 3.5in
#+RESULTS[8ea501892da9a680d09dae6c57f8da0bec56e358]:
[[file:../figures/network_tree.eps]]

\clearpage

*** Solution approach
:PROPERTIES:
:CUSTOM_ID: solution-approach
:END:

In smaller contexts, a manually design of the network suffices to meet all the
technological constraints while being reasonably cheap. This is not our case,
since the set of possible topologies is far too vast for a manual evaluation: a
programmatic strategy is then necessary to proceed.

Problems on graphs similar to the one we face are often solved using either [[ac:ilp][ILP]]
or an heuristic approach cite:Koch1998,Rehfeldt2015,Diane1993,Leitner2014. \\
The former is a powerful mathematical tool that finds the best possible solution
to the problem, but it is very demanding with respect to computational resources
and time. \\
The latter instead does not strive to give the optimum, but can hopefully
achieve decent results in a more reasonable amount of time.

A mathematical model can be written to describe the multi-layered system as a
whole, but its complexity would have made it impossible to handle by any solver,
both in terms of number of variables and constraints.

To overcome this issue a different way of designing the topology has to be
devised. Instead of positioning all the nodes at once, the proposed algorithm
would place the leaves of the tree, meaning the [[ac:dslam][DSLAM]]s, first and then move up
to the higher-level elements. \\
This is closer to what is done in practice, as each step is examined and
evaluated according to criteria, such as soundness and future-proofing of the
infrastructure, that are difficult to explain to the solver.

#+BEGIN_SRC plantuml :file ../figures/network_tree_simplified.eps :noweb yes
  <<plantuml_skin>>
  skinparam nodesep 10

  queue Backbone as b

  rectangle Mainframe as r #ff9b9b

  rectangle Head as d1 #f6ff9b
  rectangle Head as d2 #f6ff9b
  rectangle Head as d3 #f6ff9b
  rectangle Head as d4 #f6ff9b
  rectangle Head as d5 #f6ff9b
  rectangle Head as d6 #f6ff9b

  interface " " as c1
  interface " " as c2
  interface " " as c3
  interface " " as c4
  interface " " as c5
  interface " " as c6
  interface " " as c7
  interface " " as c8
  interface " " as c9
  interface " " as c10
  interface " " as c11
  interface " " as c12
  interface " " as c13
  interface " " as c14
  interface " " as c15
  interface " " as c16
  interface " " as c17
  interface " " as c18

  b -- r

  r -[dashed]- d1
  r -[dashed]- d2
  r -[dashed]- d3
  r -[dashed]- d4
  r -[dashed]- d5
  r -[dashed]- d6

  d1 -- c1
  d1 -- c2
  d1 -- c3
  d2 -- c4
  d2 -- c5
  d2 -- c6
  d3 -- c7
  d3 -- c8
  d3 -- c9
  d4 -- c10
  d4 -- c11
  d4 -- c12
  d5 -- c13
  d5 -- c14
  d5 -- c15
  d6 -- c16
  d6 -- c17
  d6 -- c18

  d1 -[hidden] d2
  d2 -[hidden] d3
  d3 -[hidden] d4
  d4 -[hidden] d5
  d5 -[hidden] d6

  c1 -[hidden] c2
  c2 -[hidden] c3
  c3 -[hidden] c4
  c4 -[hidden] c5
  c5 -[hidden] c6
  c6 -[hidden] c7
  c7 -[hidden] c8
  c8 -[hidden] c9
  c9 -[hidden] c10
  c10 -[hidden] c11
  c11 -[hidden] c12
  c12 -[hidden] c13
  c13 -[hidden] c14
  c14 -[hidden] c15
  c15 -[hidden] c16
  c16 -[hidden] c17
  c17 -[hidden] c18
#+END_SRC

#+LABEL: fig:network_tree_simplified
#+CAPTION: Each /head/ aggregates the traffic of all nodes in its /cluster/.
#+ATTR_LATEX: :height 2.5in
#+RESULTS[5085dfc30f26ccf8321faf35dc8ee483110cc158]:
[[file:../figures/network_tree_simplified.eps]]

The network topology moves then from the one in [[autoref:fig:network_tree]] to the
simplified setting of autoref:fig:network_tree_simplified.

As apparent in the diagram the solver must now take into consideration the cost
of the nodes that have been omitted from the tree. This is accounted as a lump
sum for the connection of each network switch, called from now on cluster
/head/, to the mainframe both in terms of cables and intermediate nodes.

Both the exact and approximate approach that will be proposed in this thesis
will build the access network in this fashion, starting from the periphery and
moving towards the core of the network.

All relevant parameters have been collected in [[autoref:quantities_constraints]] and
will be taken for granted from now on.

#+NAME: quantities_constraints
#+CAPTION: Problem parameters, divided in topology specific ones, technological limits and costs.
#+ATTR_LATEX: :align cl
| Variable        | Description                                                   |
|-----------------+---------------------------------------------------------------|
| $G = (V, \, E)$ | Graph describing the city topology                            |
| $T \subseteq V$ | Set of terminal nodes                                         |
| $l_e = l_{ij}$  | Length of edge $e = (i,\,j) \in E$                            |
| $u_i$           | Number of users at terminal $i \in T$                         |
|-----------------+---------------------------------------------------------------|
| $d_M$           | Maximum distance from a terminal and its root                 |
| $n_M$           | Maximum number of terminals per tree                          |
|-----------------+---------------------------------------------------------------|
| $c_r$           | Cost of a single subtree root node, plus mainframe connection |
| $c_f$           | Cost of a fiber optic cable per meter                         |
| $c_e$           | Cost of roadwork excavation per meter                         |

\clearpage
*** ILP formulation
In order to express the optimization problem in a convenient way, we arrange our
data as follows.

A direct graph $G^\prime = (V \cup \{r\},\, A)$ is induced on top of the $G$, where
the set of arcs $A$ is defined as follows.

#+NAME: induction_G
\begin{equation}
  A = \left\{ (i,\,j),\, (j,\,i) ~~ \forall \{i, j\} \in E \right\} \cup
  \left\{ (r,\,j) ~ \forall j \in V \right\}
\end{equation}

In autoref:induction_G each undirected edge in $E$ is doubled with the two
corresponding directed arcs; then an artificial node $r$ is added to the
vertices set and connected to each of the nodes in $V$.

Each arc $(i,\,j) \in A$ is assigned a length $l_{ij}$, in meters, given by the
geographical distance between its endpoints. Artificial arcs $(r,\,j)$ do not
correspond to physical connections and so $l_{rj} = 0 ~~ \forall j \in V$.

With this setup our network access configuration will simply be a direct tree, or
/arborescence/, with root in $r$, as depicted in autoref:fig:tree_network.

#+BEGIN_SRC plantuml :file ../figures/ilp_graph_reduced.eps :noweb yes
  <<plantuml_skin>>
  skinparam nodesep 10

  skinparam ArrowFontSize 25
  skinparam UsecaseFontSize 25
  hide empty description

  usecase "r" as r #ff9b9b

  usecase " " as d1 #f6ff9b
  usecase " " as d2 #f6ff9b
  usecase " " as d3 #f6ff9b
  usecase " " as d4 #f6ff9b
  usecase " " as d5 #f6ff9b
  usecase "i" as d6 #f6ff9b

  usecase " " as c1
  usecase " " as c2
  usecase " " as c3
  usecase " " as c4
  usecase " " as c5
  usecase " " as c6
  usecase " " as c7
  usecase " " as c8
  usecase " " as c9
  usecase " " as c10
  usecase " " as c11
  usecase " " as c12
  usecase " " as c13
  usecase " " as c14
  usecase " " as c15
  usecase " " as c16
  usecase " " as c17
  usecase " " as c18

  usecase " " as n1
  usecase " " as n2
  usecase " " as n3
  usecase " " as n4
  usecase " " as n5
  usecase " " as n6
  usecase " " as n7
  usecase " " as n8
  usecase " " as n9
  usecase " " as n10
  usecase " " as n11
  usecase " " as n12
  usecase " " as n13
  usecase " " as n14
  usecase " " as n15
  usecase " " as n16
  usecase " " as n17
  usecase " " as n18
  usecase " " as n19
  usecase " " as n20
  usecase " " as n21
  usecase " " as n22
  usecase " " as n23
  usecase " " as n24

  r -[#ff5050]->> d1
  r -[#ff5050]->> d2
  r -[#ff5050]->> d3
  r -[#ff5050]->> d4
  r -[#ff5050]->> d5
  r -[#ff5050]->> d6 : "(r, i)"

  d1 -->> c1
  d1 -->> c2
  d1 -->> c3
  d2 -->> c4
  d2 -->> c5
  d2 -->> c6
  d3 -->> c7
  d3 -->> c8
  d3 -->> c9
  d4 -->> c10
  d4 -->> c11
  d4 -->> c12
  d5 -->> c13
  d5 -->> c14
  d5 -->> c15
  d6 -->> c16
  d6 -->> c17
  d6 -->> c18

  c1  -->> n1
  c1  -->> n2
  c2  -->> n3
  c3  -->> n4
  c4  -->> n5
  c5  -->> n6
  c5  -->> n7
  c6  -->> n8
  c7  -->> n9
  c8 -->> n10
  c8 -->> n11
  c8 -->> n12
  c9 -->> n13
  c9 -->> n14
  c10 -->> n15
  c11 -->> n16
  c11 -->> n17
  c12 -->> n18
  c14 -->> n19
  c15 -->> n20
  c15 -->> n21
  c16 -->> n22
  c18 -->> n23
  c18 -->> n24

  d1 -[hidden] d2
  d2 -[hidden] d3
  d3 -[hidden] d4
  d4 -[hidden] d5
  d5 -[hidden] d6

  c1 -[hidden] c2
  c2 -[hidden] c3
  c3 -[hidden] c4
  c4 -[hidden] c5
  c5 -[hidden] c6
  c6 -[hidden] c7
  c7 -[hidden] c8
  c8 -[hidden] c9
  c9 -[hidden] c10
  c10 -[hidden] c11
  c11 -[hidden] c12
  c12 -[hidden] c13
  c13 -[hidden] c14
  c14 -[hidden] c15
  c15 -[hidden] c16
  c16 -[hidden] c17
  c17 -[hidden] c18
#+END_SRC

#+LABEL: fig:tree_network
#+CAPTION: In the final solution, additional arcs $(r,\, i)$ connect artifical node $r$ to all the roots, making the whole structure an arborescence, instead of a forest.
#+ATTR_LATEX: :width \linewidth
#+RESULTS[73e203a14ca9323ed263eab6c671feafb662aded]:
[[file:../figures/ilp_graph_reduced.eps]]

Because of the system requirements we also have to keep track of the distance
$d_i$ of each node $i \in V \cup \{r\}$ from its head and the number of users $n_e$ served
by each link in $A$, ensuring they do not exceed their limits.

Given this setup, our optimization problem can be written as follows.

\clearpage

\begin{align}
  \min_{ \stackrel{\{x_e\}_{e \in E}}{\{u_t\}_{t \in T}}}
  & \left( \sum_{t \in T} d_t \, u_t \right) \, c_c
    + \left( \sum_{e \in E} x_e \, l_e \right) \, c_e
    + \left( \sum_{e \in \delta^+(r)} x_e \right) \, c_r
    \label{eq:obj_function} \\[0.8em]
  \text{subject to ~~}
  & \sum_{e \in \delta^-(j)} x_e ~
    \begin{dcases}
      = 0 & j = r \\
      = 1 & j \in T \\
      \le 1 & j \in V \setminus T
    \end{dcases} \label{eq:single_arc_in} \\[0.5em]%
    % & \forall j \in V, \sum_{e \in \delta^+(j)} x_e
    % \le \left( \sum_{e \in \delta^-(j)} x_e \right)
    % \, \max_{v \in V} \left| \delta^+(v) \right|
    % \label{eq:nodes_reachability} \\[0.5em]
  & \sum_{e \in \delta^+(r)} x_e \ge 1
    \label{eq:r_active} \\[0.5em]
  & \forall j \in V \cup \{r\}, ~ d_j \le \left( \sum_{e \in \delta^-(j)} x_e \right) d_M
    \label{eq:distance_upper_limit} \\[0.2em]
  & \forall (i,\,j) \in A ~
    \begin{dcases}
      ~ d_j - d_i \ge l_{ij} ~ x_{ij} - d_M \, (1 - x_{ij}) \\[0.2em]
      ~ d_j - d_i \le l_{ij} ~ x_{ij} + d_M \, (1 - x_{ij})
    \end{dcases}
  \label{eq:distance_progression} \\[1.5em]
  & \forall e \in A,\, n_e \le x_e \, n_M
    \label{eq:n_terminals_upper_limit} \\
  & \sum_{e \in \delta^-(j)} n_e - \sum_{e \in \delta^+(j)} n_e =
    \begin{dcases}
      ~ p_j & j \in T \\[0.2em]
      ~ 0 & j \in V \setminus T
    \end{dcases} \label{eq:n_flow_balance} \\[0.5em]
  & \sum_{e \in \delta^+(r)} n_e = \sum_{i \in T} u_i
    \label{eq:root_sink} \\[0.8em]
  & \forall e \in A, \, x_e \in \{0, \, 1\}, \, n_e \in \mathbb{N} \cup \{0\}
    \label{eq:var_domain_1} \\[0.5em]
  & \forall j \in V \cup \{r\}, \, d_j \ge 0
    \label{eq:var_domain_2}
\end{align}

To clear the notation, we have defined functions $\delta^+, \, \delta^-: V \rightarrow
\mathbb{P}(A)$ associating each node with the out-going and in-going edges
respectively.

\begin{equation}
  \begin{split}
    \delta^+(j) &= \left\{ (j,\,k) \in A \right\} \\
    \delta^-(j) &= \left\{ (i,\,j) \in A \right\} \\
  \end{split}
\end{equation}

The problem is set to minimize the objective function autoref:eq:obj_function
that sums up the cost of optical fiber lines, roadworks and the total price of
/head/ switching units.

The first constraint autoref:eq:single_arc_in forces the terminals to be connected
to our network and sets the number of in-going arcs to be at most one, which is a
necessary condition for the network to be a directed tree.

As the leaves are set to be part of the network, $r$ has to be as well by
autoref:eq:r_active. It will then be the root node of the resulting tree, as by
construction of $G^\prime$ node $r$ has no in-going arcs.

The next equations deal with the variables $d_j$, distance from the tree root.
First, in autoref:eq:distance_upper_limit this quantity is limited by $d_M$ if
the node is reached by the network, otherwise it is set to zero. \\
On the other hand autoref:eq:distance_progression guarantees the consistency of
this metric between two connected nodes, forcing target node distance to be the
source one plus the link length. \\
Implicitly the latter prevents the resulting network to have loops, necessary
for our solution to be a proper arborescence.

The last needed metric for limiting the possible solutions is the number of
users each link can handle, $n_M$. This upper limit for $n_e$ is set in
autoref:eq:n_terminals_upper_limit such that it has to hold only for active
edges, and then the count of the users from leaves to each sub-root is performed
in autoref:eq:n_flow_balance, which has the same form as a flow-conservation
clause. \\
All such flows must converge towards the root $r$ for autoref:eq:root_sink: this
forces the network to be connected, finally giving it the wanted shape.

Variable domains are eventually specified in autoref:eq:var_domain_1 and
autoref:eq:var_domain_2.

\bigbreak

Overall, the model requires $|V| + 1 + 4 \, |E|$ variables and $3\, |V| +
2\,|T| + 4 \, |E| + 1$ constraints, both of which are $O(|V|)$ for sparse graphs like the one we are working on.

*** Heuristic algorithm
:PROPERTIES:
:CUSTOM_ID: methodology-heuristic
:END:

The mathematical problem described in the previous section can be effectively
solved only for small instances, i.e. sparse graphs with up to one hundred
nodes. \\
In fact, when tested on our specific case with tens of thousands of nodes and
edges, the program could not output the solution within a reasonable amount of
time and resources.

An heuristic approach had to be devised: for the peculiarities of the problem it
is indeed suitable a \emph{greedy} approach, inspired by hierarchical clustering.

The basic idea is to progressively join single nodes of the graph in bigger and
bigger /clusters/ until the total cost decreases: once a merge results in a more
expensive network, the algorithm stops. \\
Such merges are allowed whenever the mentioned [[ac:qos][QoS]] constraints are met and
adjacent subsets are preferred. To be precise, distance between each couple of
groups is defined as the distance of the closest elements: this is done to
privilege more cohesive and compact pairs.

This procedure is repeated until all possible choices have been considered or
the next merge increases the cost of the network.

Pseudo-code is available in [[autoref:lst:alg:heuristic]]. As defined in autoref:tab:quantities_constraints, parameters $n_M$ and $d_M$ are the maximum number of nodes per cluster and the maximum distance between vertices in the same cluster, respectively.

\begin{bigalgorithm}
  \label{lst:alg:heuristic}
  \begin{algorithmic}
    \caption{Heuristic solver}
    % \State /* \quad \textsc{init} phase \quad */
    \State $C=\emptyset$
    \State $\forall\, t \in T$ add singleton $\{t\}$ to $C$
    \State mark all couples $C_i, C_j \in C^2$ as mergeable
    \State cost = \Call{objective\_function}{$C$}
    \State
    \State stop = False
    \Repeat
    % \State /* \quad \textsc{iteration} phase \quad */
    \State pick $C_i$ and $C_j$ the two closest clusters in $C$
    \State $d_{ij}$ = diameter of cluster $C_i \cup C_j$
    \State $n_{ij}$ = number of users inside $C_i \cup C_j$
    \If {$d_{ij} < 2 \, d_M$ and $n_{ij} < n_M$}
    \State $C^\prime = \{C_1, \ldots, C_i \cup C_j, \ldots \}$
    \State current\_cost = \Call{objective\_function}{$C^\prime$}
    % \State /* \quad \textsc{performance} stop condition \quad */
    \If {current\_cost > cost}
    \State stop = True
    \Else
    \State $C = C^\prime$
    \EndIf
    \State merge $C_i$ and $C_j$
    \Else
    \State mark the couple $C_i$ and $C_j$ as unmergeable
    \EndIf
    % \State /* \quad \textsc{exhaustion} stop condition \quad */
    \If {$\nexists \, C_i, C_j \in C^2$ mergeable}
    \State stop = True
    \EndIf
    \Until { stop = False }
    \State \Return $C$
  \end{algorithmic}
\end{bigalgorithm}

The cost of each sub-network is not evaluated on the best possible
configuration, but instead goes for a sub-optimal one. \\
This is required for the algorithm to be feasible, as the Steiner-tree-like
problem that it has to be solved in order to connect all cluster nodes to a
common sub-root is yet again too complex.

As it can be seen in [[autoref:lst:alg:heuristic_obj]], each node close enough to the
cluster is evaluated as a candidate root of the corresponding spanning tree. The
network is then simply built joining the minimum paths between the best of those
and the terminals of the set.

\begin{bigalgorithm}
  \label{lst:alg:heuristic_obj}
  \begin{algorithmic}
    \caption{Approximated objective function}
    \Function{objective\_function}{$C$}
    \State total\_cost = 0
    \ForAll{$c \in C$}
    \State best\_cost = $+\infty$
    \ForAll{$v \in V$ close to $c$}
    \State $T_v = \bigcup_{t \in C} \text{minimum path from } v \text{ to } t$

    \State $\text{cost}_v = \text{cable cost of } T_v + \text{excavation cost of } T_v$
    \If {$\text{cost}_v < \text{best\_cost}$ }
    \State $\text{best\_cost} = \text{cost}_v$
    \EndIf
    \EndFor
    \State total\_cost += best\_cost
    \EndFor
    \State \Return total\_cost
    \EndFunction
  \end{algorithmic}
\end{bigalgorithm}

For now all these approximations are mandatory for the algorithm to be fast
enough to deal with our case of study, but in [[autoref:results-network_design]]
they will prove to be good ones, i.e. to be close to the theoretical optimum.

** Network optimization
:PROPERTIES:
:CUSTOM_ID: methodology-network_optimization
:END:

#+BEGIN_SRC org :exports none
  - network structure
    - flow control only viable tuning of the logical network
    - components in deeper focus
  - training approach
    - definition of objective function <~ game theory applied
    - waterfilling
    - heuristic waterfilling-inspired approach
#+END_SRC

Previous optimization steps returned a plausible topology for Aachen city access
network.

As mentioned earlier, the next step we take is to optimize it, in order to
assess whether the more flexible framework provided by [[ac:sdn][SDN]] can benefit the
overall performance.

*** Network structure
As presented in autoref:methodology-network_design, the obtained network
topology is organized in a hierarchical tree of switches, whose task is to merge
all uplink communications towards the mainframe and split the downlink ones
among the various destinations.

This structure resembles what was previously described in
autoref:fig:network_tree, and is further detailed in
autoref:fig:simulator_downlink and autoref:fig:simulator_uplink.

#+NAME: fig:simulator_downlink
#+BEGIN_SRC plantuml :file ../figures/simulator_downlink.eps :noweb yes
  skinparam nodesep 10
  skinparam ranksep 30
  <<plantuml_skin>>
  left to right direction

  node "DSLAM" as dslam1
  node "DSLAM" as dslam2
  node "DSLAM" as dslam3

  node ROUTER {
  queue "CTR" as ROUTER_ctr1 #f6ff9b
  queue "CTR" as ROUTER_ctr2 #f6ff9b
  queue "CTR" as ROUTER_ctr3 #f6ff9b
  queue "NIC" as ROUTER_queue
  queue "NIC" as interface1
  queue "NIC" as interface2
  queue "NIC" as interface3
  }

  database "Server" as server1
  database "Server" as server2

  node "Mainframe" as mf
  dslam1 <-- interface1
  dslam2 <-- interface2
  dslam3 <-- interface3

  interface1 <-- ROUTER_ctr1
  interface2 <-- ROUTER_ctr2
  interface3 <-- ROUTER_ctr3

  ROUTER_ctr1 <-- ROUTER_queue
  ROUTER_ctr2 <-- ROUTER_queue
  ROUTER_ctr3 <-- ROUTER_queue

  ROUTER_queue <-- mf

  cloud "Public\nInternet" as internet
  mf <-- internet

  internet <-- server1
  internet <-- server2
#+END_SRC

# #+ATTR_LATEX: :width 8cm
#+CAPTION: Logical node structure for downlink traffic.
#+LABEL: fig:simulator_downlink
#+RESULTS[b9c70fa3ebb841fc5ece1117e8000300baed9947]: fig:simulator_downlink
[[file:../figures/simulator_downlink.eps]]

As shown in these diagrams, each outgoing flow passes through a controller,
whose task is to govern and limit the data rate before it enters the
[[ac:nic][NIC]]. All these units can be coordinated
by the central administrator in order to give or revoke priority from a given
source.

# controllare CBR
Since in our setting all data flows are supposed to be [[ac:cbr][CBR]], deciding bandwidth
allocation is sufficient to provide users the best service.

#+NAME: fig:simulator_uplink
#+BEGIN_SRC plantuml :file ../figures/simulator_uplink.eps :noweb yes
  skinparam nodesep 10
  skinparam ranksep 30
  <<plantuml_skin>>
  left to right direction

  node "DSLAM" as dslam1
  node "DSLAM" as dslam2
  node "DSLAM" as dslam3

  node ROUTER {
  queue "CTR" as ROUTER_ctr #f6ff9b
  queue "NIC" as ROUTER_queue
  queue "NIC" as interface1
  queue "NIC" as interface2
  queue "NIC" as interface3
  }

  database "Server" as server1
  database "Server" as server2

  node "Mainframe" as mf
  dslam1 --> interface1
  dslam2 --> interface2
  dslam3 --> interface3

  interface1 --> ROUTER_ctr
  interface2 --> ROUTER_ctr
  interface3 --> ROUTER_ctr

  ROUTER_ctr --> ROUTER_queue

  ROUTER_queue --> mf

  cloud "Public\nInternet" as internet
  mf --> internet

  internet --> server1
  internet --> server2
#+END_SRC

# #+ATTR_LATEX: :width 8cm
#+CAPTION: Logical node structure for uplink traffic.
#+LABEL: fig:simulator_uplink
#+RESULTS[760c84bff898e8caa3d4fa8fdd17e68e456dc42c]: fig:simulator_uplink
[[file:../figures/simulator_uplink.eps]]

*** Quality of Experience
:PROPERTIES:
:CUSTOM_ID: methodology-qoe
:END:

In order to improve the network, first we have to define what \emph{improvement}
means for us. We decide to maximize user [[ac:qoe][QoE]], defined as a number in $[0,\,1]$,
ranging from unusable to perfect link. Each user $i$ is then given a
\emph{utility function}, mapping available bandwidth $\rho_i$ to perceived
quality.

The functions employed in this thesis were obtained by various research groups
collecting user opinion of the Internet service under different network
conditions cite:Georgopoulos2013,Schatz2011. These studies suggest a precise
link between [[ac:qoe][QoE]] and bandwidth, described by autoref:eq:utility_general:

\begin{equation} \label{eq:utility_general}
u(\rho) = a \, \rho^b + 1
\end{equation}

where $a$ and $b$ are application specific coefficients and $\rho$ is
the assigned bandwidth.

\smallskip

More specifically, our network considers two different use-cases: traditional
web-browsing and video streaming. Videos are either Low Definition (360p),
Medium Definition (720p), or High Definition (1080p). Following \emph{Google Video Quality Report},
each one of those is experienced by 5%, 10% and 85% of
the users respectively, as shown in autoref:video_quality_report cite:GoogleVideoQualityReport.

#+NAME: video_quality_report
#+BEGIN_SRC python :noweb yes :exports results :results file output
  <<python_preamble>>

  labels = 'Low Definition (LD)', 'Medium Definition (MD)', 'High Definition (HD)'
  sizes = (5, 10, 85)
  explode = (0.1, 0.1, 0)

  fig = plt.figure(frameon=False, figsize=(4, 2))
  ax = fig.gca()
  ax.pie(sizes, explode=(0.1, 0.1, 0.1), labels=labels, autopct='%1.0f%%', startangle=0)
  ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

  out_path = "../figures/streamers_profiles.pdf"
  plt.tight_layout(pad=0)
  plt.savefig(out_path)

  # plt.show()

  print(out_path, end='')
#+END_SRC

#+CAPTION: Distribution of video quality among video streaming users cite:GoogleVideoQualityReport.
#+ATTR_LATEX: :height 2in
#+LABEL: fig:video_quality_report
#+RESULTS[011430d4994e9ce3875856bdccbe452215e40b1e]: video_quality_report
[[file:../figures/streamers_profiles.pdf]]

Parameters $a$ and $b$ are then tuned in order to properly link user perception of
the different services to available resources, as shown in autoref:fig:utilities.

#+NAME: utilities
#+BEGIN_SRC R :exports results :results file value :noweb yes
  <<R_preamble>>

  library(pracma)

  utility <- function(x, a, b) {
    return(a * `^`(x, b) + 1)
  }

  as <- c(-3.035, -4.850, -17.53, -14.98544276)
  bs  <- c(-.5061, -.6470, -1.048, -0.8780054)
  types  <- c('Streaming HD',
             'Streaming MD',
             'Streaming LD',
             'Web broswing')

  x <- logspace(2, 4, 100)

  data <- data.frame('type'=c(), 'Bandwidth'=c(), 'Utility profiles'=c())

  for (index in seq(from=1, to=length(as), by=1)) {
    current_data <- data.frame(
      'Utility profiles'=types[index],
      'Bandwidth'=x,
      'Utility'=utility(x, as[index], bs[index])
    )
    data <- rbind(data, current_data)
  }

  current <- ggplot(data, aes(x=Bandwidth, y=Utility, group=Utility.profiles)) +
    labs(x='Bandwidth [kbit/s]', linetype='Utility profiles', colour='Utility profiles') +
    scale_x_continuous(trans='log', breaks=c(100, 1000, 10000)) +
    geom_line(aes(colour=Utility.profiles, linetype=Utility.profiles)) +
    scale_color_viridis(discrete=TRUE) +
    scale_linetype_manual(values = c("dashed", "solid", "twodash", "longdash")) + my_theme

  ## print(current)

  out_path <- '../figures/utilities.pdf'
  ggsave(plot = current,
         filename = out_path,
         width = 5,
         height = 3,
         unit = 'in',
         dpi = 300,
         device = 'pdf')

  print(out_path)
#+END_SRC

#+CAPTION: Utilitis vs available bandwidth for a given service.
#+ATTR_LATEX: :height 3in
#+LABEL: fig:utilities
#+RESULTS[e0c1976a49f0fedfcf1bf50b91d3d75adcce920f]: utilities
[[file:../figures/utilities.pdf]]

Looking at the four trends, it can be seen that [[ac:hd][HD]], [[ac:md][MD]] and [[ac:ld][LD]] video streaming are in
decreasing order of bandwidth demand, as expected. Instead, traditional web
browsing puts itself between [[ac:md][MD]] and [[ac:ld][LD]].

*** Fairness on resource allocation
In order to manage the network optimally, we need to reach an operation point
$\vec{\rho}$ in the bandwidth space that balances demands of all parties
involved.

Traditionally, the \emph{proportional fairness} principle is applied when
handling different flows. According to this rule, each switching unit allocates
resources in \emph{proportion} to user request. This has proven to be a reliable
way to distribute bandwidth, but it does not take into account the
application-dependent service quality perception.

Each user tends to maximize this subjective metric, called \emph{utility},
asking for more and more bandwidth, but doing so it harms the [[ac:qos][QoS]] of its
fellows. The [[ac:isp][ISP]] has then to act as an arbiter, allocating available resources
in a fair way.

The best solution of this problem is proven to be the so-called \emph{Nash
arbitration scheme} of the \emph{game} played among these actors cite:Mazumdar1991. Such unique point satisfies all desirable properties:
symmetry, independence of irrelevant alternatives and Pareto-optimality.
Moreover, it can be found simply maximizing the product $f$ of all the utilities:
this gives us a straightforward criterion to rank all possible network
configurations. We then define

\begin{equation} \label{eq:global_function}
  f(\vec{\rho}) = \prod_i u_i(\rho_i)
\end{equation}
where $\rho_i$, \emph{i}-th component of $\vec{\rho}$, is the bandwidth
assigned to the \emph{i}-th user.

\smallbreak

In autoref:results-network_optimization we will then show if the traditional
approach to manage an access network is indeed fair or not, with respect to the
optimal strategy.

*** Flow balancing optimization
As anticipated in the previous section, the fair working point is identified as
the Nash arbitration scheme, i.e. the vector $\vec{\rho}$, that is solution of the
following mathematical problem cite:Mazumdar1991.

\begin{align}
  \argmax_{\vec{\rho}} & \log f(\vec{\rho}) = \argmax_{\vec{\rho}} \sum_{i=1}^n \log u_i(\rho_i)   \\
  \text{given~~}
                 & \sum_{i=1}^n \rho_i \le \rho_{MAX} \\
                 & \forall j \in D, \,\sum_{i \in DSLAM_j} \rho_i \le \rho_{D,\,MAX}  \label{eq:dslam_max} \\
                 & \forall j \in R, \,\sum_{i \in ROUTER_j} \rho_i \le \rho_{R,\,MAX} \label{eq:router_max}
\end{align}

where $n$ is the total number of users and each [[ac:dslam][DSLAM]] and router, belonging to
sets $D$ and $R$, are assigned a subset of users $DSLAM_j$ and $ROUTER_j$ and a
maximum bandwidth $\rho_{D,\,MAX}$ and $\rho_{R,\,MAX}$, respectively.

This can be seen as a \emph{water-filling} problem, as a limited resource
$\rho_{MAX}$ has to be allocated maximising a concave objective function.

Unfortunately, however, our case is complicated by the two additional
constraints autoref:eq:dslam_max and autoref:eq:router_max: no algorithm is
currently known in literature able to solve the problem optimally cite:Xing2018.

A sub-optimal solution has then to be searched using a heuristic procedure.
Given the monotonicity of the objective function, autoref:lst:alg:heuristic_flow
is employed.

\begin{bigalgorithm}
  \label{lst:alg:heuristic_flow}
  \begin{algorithmic}
    \caption{Flow optimization algorithm}
    \State Initialize all users, each with their utility function $u_i$
    \State Set $\rho_i = 0$, $\forall i=0, \ldots, n$
    \State Set stop\_condition = False
    \While{stop\_condition is False}
    \State Randomly choose $k$ among $\{1, ..., n\}$
    \State Perturb $\rho_k$ of a uniform random quantity in $[0,\, K]$
    \If{ $\rho_k$ does not respect constraints \autoref{eq:dslam_max} and \autoref{eq:router_max}}
    \State Revert perturbation on $k$
    \EndIf
    \If{ Objective function $f$ improvement is negligible in the last L iterations}
    \State stop\_condition = True
    \EndIf
    \State Decrement $K$
    \EndWhile
    \State
    \Return $\vec{\rho}$
  \end{algorithmic}
\end{bigalgorithm}

A randomly picked bandwidth $\rho_i$ is iteratively incremented each round of a
uniform quantity in $[0,\, K]$: such perturbation remains unless any constraint
of the mathematical problem is violated. Once the operation is no more
beneficial, i.e. the increment is below a certain tolerance, the algorithm
stops.

The rationale behind this is akin to what happens in \emph{simulated annealing},
a heuristic search algorithm where perturbation of constantly decreasing size
are applied to the starting point in the hope of converging toward a viable
solution cite:Van1987.

* Results
:PROPERTIES:
:CUSTOM_ID: results
:END:

** Geographical analysis
:PROPERTIES:
:CUSTOM_ID: results-geographical_analysis
:END:

#+BEGIN_SRC org :exports none
  + maps details (whatever): maps only here?
  + graph details
    - number of nodes (building & others)
    - number of edges
    - degree distribution
    - average node distance, population
    - ... anything basically ...
#+END_SRC

In order to obtain a decent map of the city, the two OpenStreetMap datasets
corresponding to buildings and streets of the entire state of North
Rein-Westphalia were downloaded, merged and cropped to remove anything outside
Aachen border cite:OpenStreetMap.

After those operations, the remaining 58,305 constructions and 9,759 roads were
paired with the population density information and used to draw the map in
autoref:fig:aachen_city_map.

#+LABEL: fig:aachen_city_map
#+ATTR_LATEX: :height 4.5in
#+CAPTION: Summary of all Aachen district information we will employ: building, roads positions and population distribution.
[[file:../figures/aachen_citymap.png]]

As can be appreciated in the plot, the data is indeed quite accurate and
suitable for the conversion to an abstract graph with streets as edges and road
crossing as vertices. This procedure was performed using a dedicated library
that took care of all the quirks of OpenStreetMap measures.[fn:2] For example
polygons were considered in contact up to a certain tolerance distance and
everything outside the main connected component was pruned. Moreover all nodes
close to each other less than 20m were merged: this removed many useless details
and lowered the number of variables in the upcoming analysis.

Then each building was assigned residents, i.e. users of our access network,
uniformly with respect to the area population density and building surface, as
was explained in autoref:methodology-geographical_analysis.

To integrate customers information into the road graph, a first attempt was made
where a new vertex was created for every building, but the number of variables
turned out to be too high: it was then made the decision to assign the
inhabitants of the city to the closer road crossing. \\
All long roads were split in segments, forced to be shorter than 200m: this way the
average displacement introduced via this approximation was reduced to just 50m,
tolerable for our purposes.

At the end of this pre-processing phase, the graph is made of 7,231 vertices and
9,272 edges and its complexity can be handled by our algorithms. \\
A visual representation is given in [[autoref:fig:aachen_city_graph]] that shows the
result of a small part of the city center, as tiny details could not be
otherwise discerned.

#+LABEL: fig:aachen_city_graph
#+ATTR_LATEX: :width 4in
#+CAPTION: City topology is converted into an abstract graph.
[[file:../figures/aachen_city_graph.png]]

[fn:2] See http://xiaming.me/posts/2016/12/18/process-gis-shapefile-with-graph-tools/

** Network design
:PROPERTIES:
:CUSTOM_ID: results-network_design
:END:

#+BEGIN_SRC org :exports none
  ILP results

  - CPLEX performance on the problem
    + computational time
    + number of branches
    + (ask Massimo in case)
  - show found solution for network
    + analyze performance of found solution (bandwidth, ...)
    + consideration on actual used heuristics
#+END_SRC

As was introduced in autoref:solution-approach, the design procedure is
performed starting from the edge of the network, first positioning [[acp:dslam][DSLAMs]],
then second level routers routers and finally the mainframe.

While the mathematical formulation is the same, each iteration requires
different values for the problem parameters. autoref:optimization_params
collects them all omitting the unnecessary ones, such as the fixed cost of the
single mainframe which is not relevant in our analysis.

It is worth mentioning that the cost per unit $c_r$ is split into two addends,
accounting for the physical device and its connection to the mainframe. The
price and the number of ports of the switching units match the most popular
items in the market and industry best practices cite:CiscoWAN.

#+NAME: optimization_params
#+CAPTION: Values for problem parameters in the first two iterations.
#+ATTR_LATEX: :align crrr
| Parameters     |          [[ac:dslam][DSLAM]] |         Routers | Mainframe |
|----------------+----------------+-----------------+-----------|
| $n_M$ [unit]   |             48 |             400 | -         |
| $d_M$ [m]      |          1,500 |               - | -         |
| $c_r$ [€/unit] | 1,000 + 30,000 | 15,000 + 85,000 | -         |
| $c_f$ [€/m]    |              3 |               3 | 3         |
| $c_e$ [€/m]    |            100 |             100 | 100       |

As anticipated in autoref:methodology-network_design the exact
solution to the placement optimization problems could not be obtained using [[ac:ilp][ILP]].
Even with a commercial software such as CPLEX cite:Cplex, in fact, computational
time and memory demand exceeded all resources available.

Although not conclusive, the solver provided useful insights on the valid
solution domain, specifically a lower bound for the objective function, obtained
with the countinous relaxation of problem autoref:eq:obj_function.

These limits are then compared against the configuration obtained via heuristic
algorithm, presented before in autoref:methodology-heuristic. \\
[[autoref:solution_table]] clearly shows that the heuristic result is indeed
remarkably close to the theoretical optimum and proves that the choices and
approximations made previously indeed captured all relevant features of the
problem.

#+NAME: solution_table
#+CAPTION: Cost of heuristic solution is compared to the theoretical limit given by [[ac:ilp][ILP]].
#+ATTR_LATEX: :align crr
| Problem                   | [[ac:dslam][DSLAM]] | 2nd level routers |
|---------------------------+-------+-------------------|
| Number of groups          | 1,125 |                72 |
| [[ac:ilp][ILP]] cost lower bound [M€] | 65.05 |             38.08 |
| Heuristic cost [M€]       | 67.73 |             39.38 |
| Heuristic gap             |    4% |                3% |
#+TBLFM: @5$2='(format "%d%% "(truncate (* 100 (/ (float (- @4$2 @3$2)) @3$2))));N::@5$3='(format "%d%% "(truncate (* 100 (/ (float (- @4$3 @3$3)) @3$3))));N

A visual representation of the obtained clusters, groups of devices connected to
the same switching unit, is given in [[autoref:fig:heuristic_result]] and in
autoref:fig:heuristic_mainframe. Again the map is cropped in order to scale at
the proper level of detail.

\begin{figure}[htp]
  \captionsetup[subfigure]{skip=-15pt}
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{../figures/heuristic_DSLAM.png}
    \caption{DSLAM positioning}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{../figures/heuristic_2router.png}
    \caption{Second level routers positioning}
  \end{subfigure}
  \caption{The root nodes in red are hubs for terminals, black points.}
  \label{fig:heuristic_result}
\end{figure}

#+LABEL: fig:heuristic_mainframe
#+ATTR_LATEX: :height 4.5in
#+CAPTION: The mainframe, red dot, is located in an industrial complex and is connected to all second level routers.
[[file:../figures/heuristic_mainframe.png]]

** Network optimization
:PROPERTIES:
:CUSTOM_ID: results-network_optimization
:END:

*** Plot utilities                                               :noexport:

#+NAME: optimization_plotter
#+BEGIN_SRC R :exports none :noweb yes
  <<R_preamble>>

  traditional <- read.csv("../data/optimization/traditional.csv", header = TRUE)
  traditional$type <- "Heuristic"

  heuristic <- read.csv("../data/optimization/heuristic.csv", header = TRUE)
  heuristic$type <- "Traditional"

  dataset <- rbind(traditional, heuristic)

  summary <- group_by(dataset, p_nothing, p_streaming, type) %>% summarize(obj=max(obj))
  summary$obj <- exp(summary$obj)

  summary <- summary[summary$p_streaming == p_streaming, ]
  padding <- (
    max(exp(summary$obj[summary$type == 'Traditional'])) -
    min(exp(summary$obj[summary$type == 'Traditional']))
  ) / 100

  current <- ggplot(summary, aes(x=1-p_nothing, y=obj, color=type)) +
    geom_line() +
    geom_errorbar(aes(ymin=obj - padding,
                      ymax=obj + padding)) +
    labs(x=TeX("$p_{active}$"),
         y="Objective function",
         color='Strategy') +
    scale_x_continuous(breaks=unique(summary$p_nothing),
                       labels=round(unique(summary$p_nothing), 2)) +
    scale_colour_viridis(discrete=TRUE, end=0.8) +
    my_theme

  ## print(current)

  name_tag <- gsub("\\.", "", sprintf('%.1f', p_streaming))
  out_path <- sprintf('../figures/obj_vs_p_nothing_%s.pdf', name_tag)
  ggsave(plot = current,
         filename = out_path,
         width = 5,
         height = 3,
         unit = 'in',
         dpi = 300,
         device = 'pdf')

  print(out_path)
#+END_SRC

#+NAME: utility_distribution
#+BEGIN_SRC R :exports none :noweb yes
  <<R_preamble>>

  facet_label <- labeller(p_active = function(value) {
    expression('$p_{active}$')
  })

  dataset <- read.csv("../data/optimization/utility_distribution.csv.gz", header = TRUE)

  dataset <- dataset[dataset$p_streaming == p_streaming, ]
  dataset <- dataset[dataset$p_nothing == 0.1 | dataset$p_nothing == 0.9, ]

  ## swap labels (opposite by mistake)
  library(plyr)
  dataset$type = revalue(dataset$type, c("Traditional"="Heuristic",
                                         "Heuristic"="Traditional"))

  dataset$p_active <- paste("p[active]*' = ", 1 - dataset$p_nothing, "'")

  current <- ggplot(dataset, aes(x=utility, fill=type)) +
    scale_y_continuous(trans='log1p', breaks=c(100, 1000, 10000, 25000, 60000)) +
    geom_histogram(aes(y=..density..), bins=100, position="identity") +
    labs(x='Utility', y='Probability density', title='Utility distribution') +
    facet_grid(type ~ p_active, labeller=label_parsed)  +
    scale_fill_viridis(discrete=TRUE, begin=0.2, end=0.8) +
    my_theme +
    theme(legend.position='none',
          plot.title = element_text(hjust=0.5),
          panel.spacing = unit(0.8, "lines"))

  ## print(current)

  name_tag <- gsub("\\.", "", sprintf('%.1f', p_streaming))
  out_path <- sprintf('../figures/utility_distribution_%s.pdf', name_tag)
  ggsave(plot = current,
         filename = out_path,
         width = 5,
         height = 5,
         unit = 'in',
         dpi = 300,
         device = 'pdf')

  print(out_path)
#+END_SRC

*** Actual chapter

As mentioned in autoref:methodology-network_optimization, in our experiments we
study the behaviour of our reference access network for different bandwidth
demands and service profiles.

More specifically, former point is taken care of via $p_{active}$ parameter,
that is the probability a certain user is communicating or not. In order to
describe the latter factor, instead, applications are randomly split into video
streaming and web page browsing, according to a fraction $p_{streaming}$.

Two different allocation strategies are evaluated, traditional proportional
fairness and the more sophisticated Nash arbitration scheme, computed via the
\emph{heuristic} autoref:lst:alg:heuristic_flow.

With respect to global objective function $f(\rho)$, defined in
autoref:eq:global_function, our proposed solution indeed provides a more fair
operation point than the legacy one, proving that even an approximation of the
optimum outperforms what currently done in these kinds of scenarios.

#+NAME: obj_vs_p_nothing0.1
#+BEGIN_SRC R :exports results :results file value :noweb yes
p_streaming = 0.1

<<optimization_plotter>>
#+END_SRC

#+ATTR_LATEX: :width 5in
#+LABEL: fig:obj_vs_p_nothing0.1
#+CAPTION: Performance for $p_{streaming}$ = 0.1, with $95\%$ confidence intervals.
#+RESULTS[bd24e230cc1dea840f15e7e3d2e5bb5f8565259a]: obj_vs_p_nothing0.1
[[file:../figures/obj_vs_p_nothing_01.pdf]]

This gap can be easily spotted in autoref:fig:obj_vs_p_nothing0.1,
autoref:fig:obj_vs_p_nothing0.5 and autoref:fig:obj_vs_p_nothing0.9, where
average performance across multiple runs is computed for different values of
$p_{active}$ and $p_{streaming}$.

#+NAME: obj_vs_p_nothing0.5
#+BEGIN_SRC R :exports results :results file value :noweb yes
p_streaming = 0.5

<<optimization_plotter>>
#+END_SRC

#+ATTR_LATEX: :width 5in
#+LABEL: fig:obj_vs_p_nothing0.5
#+CAPTION: Performance for $p_{streaming}$ = 0.5, with $95\%$ confidence intervals.
#+RESULTS[e3fdaf9cc2060a45849d3c969cb398773ecaeb3e]: obj_vs_p_nothing0.5
[[file:../figures/obj_vs_p_nothing_05.pdf]]

Moreover, this difference is more evident when offered traffic is higher, i.e.
when the situation is more difficult to handle from the point of view of the
administrator. This observation suggests that this novel approach can be
relevant from a practical point of view as the infrastructure size and
complexity, and thus its cost, is often dictated by worst-case scenarios.

As a final remark on these results, proposed method performance is smoother,
somewhat more predictable: again is a strong point in the field, as it is more
robust to system parameters estimation errors.

#+NAME: obj_vs_p_nothing0.9
#+BEGIN_SRC R :exports results :results file value :noweb yes
p_streaming = 0.9

<<optimization_plotter>>
#+END_SRC

#+ATTR_LATEX: :width 5in
#+LABEL: fig:obj_vs_p_nothing0.9
#+CAPTION: Performance for $p_{streaming}$ = 0.9, with $95\%$ confidence intervals.
#+RESULTS[ab87c67fc88944d1aae068b2c010aa02d7562735]: obj_vs_p_nothing0.9
[[file:../figures/obj_vs_p_nothing_09.pdf]]

\bigskip

We then analyze utility distributions for the two techniques, focusing on
extreme values of $p_{active}$ and $p_{streaming}$.

#+NAME: utility_distribution0.1
#+BEGIN_SRC R :exports results :results file value :noweb yes
  p_streaming = 0.1 ## 0.1000000 0.3666667 0.6333333 0.9000000

  <<utility_distribution>>
#+END_SRC

#+ATTR_LATEX: :width 5in
#+LABEL: fig:utility_distribution0.1
#+CAPTION: Utility distribution for $p_{streaming} = 0.1$.
#+RESULTS[200b8959dbadd32314f059647c2c2f1782f45e27]: utility_distribution0.1
[[file:../figures/utility_distribution_01.pdf]]

#+NAME: utility_distribution0.9
#+BEGIN_SRC R :exports results :results file value :noweb yes
  p_streaming = 0.9 ## 0.1000000 0.3666667 0.6333333 0.9000000

  <<utility_distribution>>
#+END_SRC

#+ATTR_LATEX: :width 5in
#+LABEL: fig:utility_distribution0.9
#+CAPTION: Utility distribution for $p_{streaming} = 0.9$.
#+RESULTS[fe671db9559a1901c24d318017548f66b990401c]: utility_distribution0.9
[[file:../figures/utility_distribution_09.pdf]]

When offered traffic is lower, as shown in autoref:fig:utility_distribution0.1,
it is apparent how realizations of utility are overall closer to one, certifying the small,
but noticeable, gain seen before for the novel approach.

When instead in autoref:fig:utility_distribution0.9 the number of active users
increases the situation is trickier to interpret: again though the proposed solution
tends to move towards the optimal point.

\bigskip

#+NAME: obj_distribution
#+BEGIN_SRC R :exports results :results file value :noweb yes
  <<R_preamble>>

  dataset <- read.csv("../data/optimization/objs.csv", header = FALSE)

  current <- ggplot(dataset, aes(x=utility)) +
    ## scale_y_continuous(trans='log1p', breaks=c(100, 1000, 10000, 25000, 60000)) +
    geom_histogram(aes(y=..density..), bins=100, position="identity") +
    labs(x='Maximum global utility', y='Probability density', title='Objective function distribution') +
    scale_fill_viridis(discrete=TRUE, begin=0.5, end=0.5) +
    my_theme +
    theme(plot.title = element_text(hjust=0.5))

  ## print(current)

  out_path <- sprintf('../figures/obj_distribution.pdf')
  ggsave(plot = current,
         filename = out_path,
         width = 5,
         height = 5,
         unit = 'in',
         dpi = 300,
         device = 'pdf')

  print(out_path)
#+END_SRC

#+ATTR_LATEX: :width 5in
#+LABEL: fig:obj_distribution
#+CAPTION: Objective function distribution for $p_{streaming} = 0.5$ and $p_{active} = 0.5$.
#+RESULTS[267c935aa7fe7a21ee0439f1be55ebbf75b0681d]: obj_distribution
[[file:../figures/utility_distribution_09.pdf]]

Despite all these promising results of proposed heuristic approach, it is currently
only a lower bound on the theoretical optimum, exact solution of the
mathematical problem. So, there is room for progress in the search of the
best working point.

* Conclusions
:PROPERTIES:
:CUSTOM_ID: conclusion
:END:

\glsresetall

This thesis discusses how to design, tune and optimize an access network from
scratch, using only topographic and demographic information.

The end-to-end approach presented, meaning mathematical models and algorithms,
can be applied to a generic problem as no particular assumption were taken about
our case of study, the city of Aachen. Here we design a traditional access
network for an [[ac:isp][ISP]], but the same techniques can be used, for example, to
implement emergency communication infrastructure for areas subjected to natural
disasters. In both situations, in fact, a number of people spread over a
geographical area need to be connected to the main Internet. Either for business
or pleasure or for calling rescue teams and families, the problem can be treated
in a similar way.

\smallbreak

Considering the first step, infrastructure design, we can assert that our model
is more complete and our solutions better than what is available in literature
at the moment. We can in fact consider properly all technological limitations of
an FTTH network and allow for ad-hoc considerations in the optimization process.
Moreover, our bounds with respect to the optimum are narrower than any
state-of-the-art approach.

\smallbreak

Once built the network, [[ac:sdn][SDN]] principles are applied to its management, entrusting
packet flow control to a central unit.

Bandwidth distribution is directed by this \emph{controller} according to a
game-theoretical framework, called \emph{Nash arbitration scheme}. This ensure
the final configuration to balance packet flows and meet all desirable
assumptions of \emph{fairness}.

Utility functions, needed to fully characterize the allocation game, are
application-specific and estimate actual [[ac:qoe][QoE]]. This is a step forward with
respect to common [[ac:qos][QoS]] metrics, as this way we maximize actual customer
satisfaction and tailor service for end user peculiarities.

Indeed this strategy pays off, as improvement with respect to the legacy
\emph{proportional fairness} strategy is measurable and significant in terms of
performance and reliability.

\smallbreak

As proved in this thesis, the adopted approach is indeed promising: future
development could consider using more connection metrics, such as delay and
jitter, since bandwidth alone cannot completely describe [[ac:qoe][QoE]] for some
applications. These works could therefore assess whether a trade-off can be made
among these quantities to better fit user requirements.

Moreover the Nash arbitration scheme, here only approximated, could be computed
exactly or, if not possible, approximated via better and more specific heuristic
algorithms.

\clearpage

# TODO check bibliography requirements
bibliographystyle:plain
bibliography:biblio.bib

* COMMENT Local variables
# Local Variables:
# org-latex-tables-booktabs: t
# eval: (flyspell-mode)
# ispell-local-dictionary: "en"
# End:
