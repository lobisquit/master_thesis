#+STARTUP: indent

#+PROPERTY: header-args :cache yes

#+OPTIONS: toc:nil title:nil

#+LATEX_CLASS: report
#+LATEX_COMPILER: pdflatex

#+LATEX_HEADER: \usepackage{charter}
#+LATEX_HEADER: \usepackage[charter]{mathdesign}

#+LATEX_HEADER: \usepackage{geometry}
#+LATEX_HEADER: \usepackage{etoolbox}
#+LATEX_HEADER: \usepackage{multirow}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \graphicspath{{../figures/}}
#+LATEX_HEADER: \usepackage{subcaption}

#+LATEX_HEADER: \usepackage{mathtools}
#+LaTeX_HEADER: \usepackage{booktabs}
#+LaTeX_HEADER: \usepackage{amsmath}

#+LaTeX_HEADER: \usepackage{algpseudocode}
#+LaTeX_HEADER: \usepackage{algorithm}

#+LaTeX_HEADER: \allowdisplaybreaks
#+LaTeX_HEADER: \def\equationautorefname#1#2\null{(#2\null)}
#+LaTeX_HEADER: \def\algorithmautorefname#1#2\null{Algorithm #2\null}
#+LATEX_HEADER: \providetoggle{images_titlepage}
#+LATEX_HEADER: \settoggle{images_titlepage}{true}

#+LaTeX_HEADER: \setlength{\parindent}{0cm}
#+LATEX_HEADER: \setlength{\parskip}{0.25em}

#+LATEX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \newenvironment{bigalgorithm}
#+LATEX_HEADER:   {% \begin{bigalgorithm}
#+LATEX_HEADER:    \begin{center}
#+LATEX_HEADER:      \refstepcounter{algorithm}% New algorithm
#+LATEX_HEADER:      \hrule height.8pt depth0pt \kern2pt% \@fs@pre for \@fs@ruled
#+LATEX_HEADER:      \renewcommand{\caption}[2][\relax]{% Make a new \caption
#+LATEX_HEADER:        {\raggedright\textbf{\ALG@name~\thealgorithm} ##2\par}%
#+LATEX_HEADER:        \ifx\relax##1\relax % #1 is \relax
#+LATEX_HEADER:          \addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##2}%
#+LATEX_HEADER:        \else % #1 is not \relax
#+LATEX_HEADER:          \addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##1}%
#+LATEX_HEADER:        \fi
#+LATEX_HEADER:        \kern2pt\hrule\kern2pt
#+LATEX_HEADER:      }
#+LATEX_HEADER:   }{% \end{bigalgorithm}
#+LATEX_HEADER:      \kern4pt\hrule\relax% \@fs@post for \@fs@ruled
#+LATEX_HEADER:    \end{center}
#+LATEX_HEADER:   }
#+LATEX_HEADER: \makeatother

#+LATEX_HEADER: \usepackage{glossaries}
#+LATEX_HEADER_EXTRA: \newacronym{pop}{PoP}{Point of Presence}
#+LATEX_HEADER_EXTRA: \newacronym{dslam}{DSLAM}{Digital Subscriber Line Access Multiplexer}
#+latex_header_extra: \newacronym{qos}{QoS}{Quality of Service}
#+latex_header_extra: \newacronym{qoe}{QoE}{Quality of Experience}
#+latex_header_extra: \newacronym{cbr}{CBR}{Constant Bitrate}
#+latex_header_extra: \newacronym{forces}{ForCES}{Forwarding and Control Element Separation}
#+latex_header_extra: \newacronym{ilp}{ILP}{Integer Linear Programming}
#+latex_header_extra: \newacronym{sdn}{SDN}{Software Defined Network}
#+latex_header_extra: \newacronym{isp}{ISP}{Internet Service Provider}
#+latex_header_extra: \newacronym{hd}{HD}{High Definition}
#+latex_header_extra: \newacronym{md}{MD}{Medium Definition}
#+latex_header_extra: \newacronym{ld}{LD}{Low Definition}

* Utility code :ignore:
** PlantUML common style                                            :ignore:
#+BEGIN_COMMENT
PlantUML skin, reusable for all diagrams
#+END_COMMENT

#+NAME: plantuml_skin
#+BEGIN_SRC plantuml :exports none
  skinparam shadowing false
  skinparam padding 1
  skinparam BoxPadding 1

  'skinparam DefaultFontName Charter
  skinparam DefaultFontName Fira Sans

  skinparam defaultTextAlignment center

  skinparam SequenceDelayFontSize 15

  skinparam Note {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Node {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Cloud {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Database {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Actor {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Activity {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam activityDiamond {
  BackgroundColor white
  BorderColor black
  FontColor       black
  }

  skinparam ArrowColor black

  skinparam State {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam SequenceParticipant {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Interface {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam SequenceLifeLine {
  BorderColor black
  BackgroundColor black
  }

  skinparam Queue {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }

  skinparam Usecase {
  BackgroundColor white
  BorderColor     black
  FontColor       black
  }
#+END_SRC

** Download university logos                                        :ignore:
#+BEGIN_COMMENT
Download all needed files for titlepage and convert them.
LaTeX support for svg files sucks.
#+END_COMMENT

#+BEGIN_SRC bash :exports none :results none
  wget https://upload.wikimedia.org/wikipedia/it/5/53/Logo_Universit%C3%A0_Padova.svg \
       -O ../figures/logo_unipd.svg

  inkscape ../figures/logo_unipd.svg --export-pdf=../figures/logo_unipd.pdf

  wget https://upload.wikimedia.org/wikipedia/commons/1/11/RWTH_Logo.svg \
       -O ../figures/logo_rwth.svg

  inkscape ../figures/logo_rwth.svg --export-pdf=../figures/logo_rwth.pdf
#+END_SRC

** Latex title page                                                 :ignore:
#+BEGIN_EXPORT latex
\newgeometry{top=1in, bottom=1in, inner=1in, outer=1in}
\begin{titlepage}
  {\Large University of Padova}
  \vspace{5mm}

  {\Large Department of Information Engineering}

  \begin{center}
    \vspace{1cm}
    {\Large \textsl{Master degree in Telecommunication Engineering}} \\
    \vspace{1cm}
    {\scshape\huge Traffic flow optimization \\[0.3em] for urban xDSL based access networks }

    \iftoggle{images_titlepage}{
      \vspace{1cm}
      \begin{figure}[h]
        \centering
        \includegraphics[height=5cm]{logo_unipd.pdf}
        \vspace{0.5cm} \\
        \includegraphics[height=2cm]{logo_rwth.pdf}
      \end{figure}
    }

  \end{center}

  \vfill
  \hspace{0.5cm}%
  \renewcommand{\arraystretch}{2.5}
  \begin{tabular}{lr}
    \large \textsl{Author}               & \hspace{5mm} \large Enrico Lovisotto      \\
    \large \textsl{Internal supervisor}  & \hspace{5mm} \large Prof. Andrea Zanella  \\
    \large \textsl{External supervisors} & \hspace{5mm} \large Prof. Petri Mähönen  \\
                                         & \hspace{5mm} \large Dr. Ljiljana Simić   \\
  \end{tabular}
  \vspace{1cm}

  \hfill{\large February 6, 2019} \vspace{2mm}

  \hfill{\Large Academic year 2018-2019 \par}
\end{titlepage}

\restoregeometry
#+END_EXPORT

** Asymptote preamble                                               :ignore:
#+NAME: asymptote_preamble
#+BEGIN_SRC asymptote :exports none
  settings.outformat="pdf";

  texpreamble("\usepackage[sfdefault]{Fira Sans}");
  texpreamble("\usepackage{newtxsf}");

  // texpreamble("\usepackage{charter}");
  // texpreamble("\usepackage[charter]{mathdesign}");
#+END_SRC

** Python preamble                                                  :ignore:
#+NAME: python_preamble
#+BEGIN_SRC python :exports none
  import matplotlib.pyplot as plt

  from matplotlib import rcParams

  font_spec = {
      'font.family':'sans-serif',
      'font.sans-serif':['Fira Sans'],
      'font.weight': 'regular',
      'axes.titleweight': 'regular'
  }
  rcParams.update(font_spec)
#+END_SRC

** R preamble                                                       :ignore:
#+NAME: R_preamble
#+BEGIN_SRC R :exports none
  .libPaths("/opt/R/x86_64-pc-linux-gnu-library")

  library(reshape2)
  library(ggplot2)
  library(scales)
  library(extrafont)
  library(gridExtra)
  library(latex2exp)
  library(readr)
  library(dplyr)
  library(data.table)
  library(purrr)

  loadfonts()

  my_theme <- theme_bw() +
    theme(
      text = element_text(family = "Fira Sans")
    )
#+END_SRC
* Introduction
:PROPERTIES:
:CUSTOM_ID: introduction
:END:

#+BEGIN_SRC org :exports none
  + background: what are we talking about?
    - SDN => self-optimizing networks
    - flow balancing
    - routing adaptation

  + what they do now?
    - summary of state of the art, /basically/

  + shortcomings in current knowledge / solutions
    - limits of SDN over traditional networks: lack of negative results
    - use of abstract topologies ~> this one is obtained through optimization process

  + what are we gonna prove?
    - 99% if the networks are very simple, meant to be more flow aggregators and less clever routers
    - SDN are not inherently good: /probably/ traditional solutions are good in 99% of the networks
    - SDN are relevant when the complexity of the network grows
#+END_SRC

# SDN

Since the creation of the public internet, the nature of the network layer of
the protocol stack had been static. Each route was either set by hand or
discovered by the device itself: in both cases no control was given to the
network administrator to change this behaviour in case of load variations or
poor performance.

In the last year, this inflexible paradigm was questioned, as the complexity and
sheer amount of data crossing each connection increased exponentially.
cite:CiscoVisualNetworking

#+NAME: fig:internet_user_growth
#+BEGIN_SRC asymptote :file ../figures/internet_user_growth.pdf :noweb yes
  <<asymptote_preamble>>

  import graph;

  size(8cm, 8cm, IgnoreAspect);

  int[] years = { 2005,
                  2006,
                  2007,
                  2008,
                  2009,
                  2010,
                  2011,
                  2012,
                  2013,
                  2014,
                  2015,
                  2016,
                  2017,
                  2018 };

  real xmin = 0.5;
  real xmax = 8;

  real[] people = { 1.018, // 2005
                    1.093, // 2006
                    1.319, // 2007
                    1.574, // 2008
                    1.802, // 2009
                    1.971, // 2010
                    2.267, // 2011
                    2.497, // 2012
                    2.802, // 2013
                    3.079, // 2014
                    3.366, // 2015
                    3.696, // 2016
                    4.156, // 2017
                    4.502, // 2018
  };

  real ymin = 0.5;
  real ymax = 8;

  draw(graph(x=years, y=people, join=operator ..), red + linewidth(1.1pt));

  xaxis(axis=YEquals(0.5),
        xmin=years[0] - 1,
        xmax=years[years.length - 1] + 2,
        ticks=LeftTicks(Label(fontsize(8)),
                        beginlabel=false,
                        Step=2,
                        step=1,
                        modify=OmitTickInterval(2019, inf)),
        arrow=Arrow());

  yaxis(axis=Left,
        ymin=0.5,
        ymax=people[people.length - 1] + 0.5,
        ticks=RightTicks(format=Label("$%.4g \times 10^{\,9}$", fontsize(8)),
                        modify=OmitTickInterval(4.6, inf),
                        extend=false,
                        beginlabel=true),
        arrow=Arrow);

  label(L="Internet users progression",
        position=point(N),
        align=shift(0, 1) * N,
        p=fontsize(10));
#+END_SRC

#+CAPTION: Number of internet users has steadily increased for the past fifteen years.
#+ATTR_LATEX: :width 8cm
#+LABEL: fig:internet_user_growth
#+RESULTS[741d558b5f3167e9b663ac66fa2b42b26986980f]: fig:internet_user_growth
[[file:../figures/internet_user_growth.pdf]]

The idea behind this revolution was to decouple the \emph{data plane}, the
actual physical devices forwarding packets, and the \emph{control plane},
responsible for the actual routing decision. The latter is placed in one or mode
devices, called \emph{controllers}, whose task is to orchestrate involved
routers and switches based on current and forecast network status.

This separation moves the routing logic from the single component to a
centralized and fully programmable entity, that can perform its decisions based
on an overall view of the network dynamics.

In a moment of congestion of a particular link, for example, some data flows can
be diverted to other paths, increasing [[ac:qos][QoS]] for all users. This can be very
interesting in cable networks, where packet gridlock is indeed the main issue
for administrators.

#+CAPTION: Data flow of users (squares) are tuned and managed by the SDN controller via the routers (circles).
#+ATTR_LATEX: :width 8cm
#+LABEL: fig:network_planes
[[file:../figures/network_planes.pdf]]

# brief history of the concept

Although the concept had been considered for many years, its first
implementations were not successful from an adoption point of view. Standards
like [[ac:forces][ForCES]], published by IETF in 2004, failed to gain traction because of the
security concerns, regarding possible attacks against the [[ac:sdn][SDN]] controller and
because vendors were not willing to adopt a common interface, for fear of
competition.

The first widespread example of open-source API was OpenFlow, proposed in 2008
by the Stanford computer science department. cite:Mckeown2008 After its
definition, a multitude of applications were written on top of this new
standard, such as NOX network operating system cite:Gude2008, and this helped
further adoption to the point where OpenFlow is now considered industry
standard.

Many data centers all over the world experimented successfully with it
cite:Vaughan2011,Uppal2010, in fact, and report significant improvements in
their infrastructure management and performance.

# shortcomings of proposed solution and applications

Currently there is much hype about OpenFlow, since they are seen as a tool to
overcome the ``ossification of the Internet'' cite:Hakiri2014, making the whole
system more flexible to manage.

This is especially interesting since users number has steadily continued to grow
in the past years, as shown previously in autoref:fig:internet_user_growth.
Moreover, the traffic all these people are requesting to the Internet
infrastructure is not yet expected to stabilize, according to \textsc{cisco}.
cite:CiscoVisualNetworking.

#+NAME: fig:internet_traffic_growth
#+BEGIN_SRC asymptote :file ../figures/internet_traffic_growth.pdf :noweb yes
  <<asymptote_preamble>>

  import graph;

  size(8cm, 8cm, IgnoreAspect);

  int[] years = { 2017,
                  2018,
                  2019,
                  2020,
                  2021,
                  2022 };

  real xmin = 0.5;
  real xmax = 8;

  real[] traffic = { 122, // 2017
                     156, // 2018
                     201, // 2019
                     254, // 2020
                     319, // 2021
                     396, // 2022
  };

  real ymin = 0.5;
  real ymax = 8;

  draw(graph(x=years, y=traffic, join=operator ..), green + linewidth(1.1pt));

  xaxis(axis=YEquals(0.5),
        xmin=years[0] - 1,
        xmax=years[years.length - 1] + 2,
        ticks=LeftTicks(Label(fontsize(8)),
                        beginlabel=false,
                        Step=2,
                        step=1,
                        modify=OmitTickInterval(years[years.length - 1] + 1, inf)),
        arrow=Arrow());

  yaxis(axis=Left,
        ymin=0.5,
        ymax=traffic[traffic.length - 1] + 100,
        ticks=RightTicks(format=Label("$%.4g$EB/month", fontsize(8)),
                        modify=OmitTickInterval(401, inf),
                        extend=false,
                        beginlabel=true),
        arrow=Arrow);

  label(L="Internet traffic projection",
        position= point(N),
        align=shift(0, 1) * N,
        p=fontsize(10));
#+END_SRC

#+CAPTION: Internet traffic is expected to explode in the next years.
#+ATTR_LATEX: :width 8cm
#+LABEL: fig:internet_traffic_growth
#+RESULTS[4b42a8c1b680a5f504ed404b1508d1409846c631]: fig:internet_traffic_growth
[[file:../figures/internet_traffic_growth.pdf]]

Given the current demand for connectivity and bandwidth, [[ac:sdn][SDN]] can be a
ground-breaking approach to further improve the networks performance at every
level.

However, as every tool, its makings have to be coupled with a robust knowledge
on its limits. From a methodological point of view, this is necessary in order
to make the most out of [[ac:sdn][SDN]], since alleged once-and-for-all solutions often
stumble when context changes from the expected one.

As mentioned before, [[ac:sdn][SDN]] were indeed useful when dealing with very high
bandwidth link management in scenarios that are complex either because of the
topology or applications demand. cite:Singh2015

In this thesis we aim then to understand what happens in the other side of the
spectrum, i.e. when dealing with static and simple access networks. At the
moment no study has been devoted to understand and quantify how much a
controller can improve user [[ac:qos][QoS]] in these simple, but very common, settings.

We specifically focused on the access network of Aachen, historical city in the
German state of North Rein-Westphalia. As the actual schematics are not
available to the general public, our network topology was inferred, solving an
optimization problem, as residential buildings and population distribution
across the area, performing a so-called \emph{educated guess}.

The network was run in a custom event driven simulator, both with and without a
controller, in order to assess the improvement introduced by its action.

\smallskip
This thesis is structured as follows.
First, an overview of past works related to this thesis scope is provided in
autoref:state_of_art. Then, autoref:methodology introduces the theoretical
instruments employed in this analysis, whose results are collected and commented
in autoref:results. Final remarks and considerations are eventually discussed in
autoref:conclusion.

* State of the art
:PROPERTIES:
:CUSTOM_ID: state_of_art
:END:

#+BEGIN_SRC org :exports none
  One subsection for each of the macro-areas

  - maps -> network topology
    - Steiner tree
    - ...

  - flow control
    - fairness in network management ~> Nash arbitration point

  - heuristic control of the network
#+END_SRC

As mentioned in autoref:introduction, the first step of this thesis is the
estimation of the Aachen city network, given publicly available information on
city topology and population density.

The \emph{educated guess} was performed solving an optimization problem,

* Methodology
:PROPERTIES:
:CUSTOM_ID: methodology
:END:

This section will discuss which theoretical framework and tools that have been used
throughout the analysis and the motivation behind them.

First, in autoref:methodology-geographical_analysis, we will analyze the Aachen
building and road map in order to design, in autoref:methodology-network_design,
a proper access network based on city topology and population density.

Once obtained a suitable structure, the controller is tuned in order to enhance
network performance for all its users.

** Geographical analysis
:PROPERTIES:
:CUSTOM_ID: methodology-geographical_analysis
:END:

#+BEGIN_SRC org :exports none
  OpenStreetMap ~> roads + buildings graph: only methodological consideration

  + cutting NRW maps with Aachen border
  + selecting roads & buildings type
  + ~s2g~ to obtain the graph ~> cite stuff using this approach
    - road polygons to edges
    - intersections as nodes
  + adding building to the graph
    - splitting roads
    - population estimated based on district population, building area
#+END_SRC

The city of Aachen is located in the north-west of Germany, in state of North
Rhine-Westphalia. Its district has a surface of 160.85km² and a population of
244,951 citizens.

Although medium sized, the city is an important telecommunication node between
Germany and the neighbour countries of Belgium and Netherlands. The LambdaNet
backbone, owned by /euNetworks Managed Services GmbH/, crosses in fact the city
and provides direct connection to public Internet. Its map, built by ``The
Internet Topology Zoo'' project cite:topology_zoo, has been plotted in
autoref:fig:lambdanet.

#+LABEL: fig:lambdanet
#+ATTR_LATEX: :width 10cm
#+CAPTION: LambdaNet is a national backbone that serves all major German cities and connects the country to the rest of Europe.
[[../figures/german_backbone.pdf]]

In this thesis we will then suppose that the access network connects all Aachen
buildings to this main backbone via a single [[ac:pop][PoP]], located in the industrial
district of the city.

Unfortunately, schematics for such network are not publicly available, so we
have to perform what it is called an /educated guess/, meaning a good estimation
based on available information.

The evaluation will be performed using OpenStreetMap cite:OpenStreetMap in
conjunction with the /Open Data Portal/ of the city of Aachen: [fn:1] the former
provides buildings and roads positions, while the latter describes how
population is distributed across the city districts.

[fn:1] Please refer to http://daten.aachen.de for further information and licensing.


All this information can be visualized in the map of
[[autoref:fig:aachen_city_map]], in the autoref:results-geographical_analysis.

\bigbreak

Due to the level of detail of these datasets, two assumptions are needed to
proceed and extract a reasonable diagram for the access city network.

First, we suppose cables to be put along streets and not to cross (even public)
terrains. This is common practice, since roadworks are usually exploited to
perform maintenance and build new parts of the communication network.

Second, we consider the population of a given area to be uniformly distributed
across a fraction of its buildings, so-called /residential/ ones, randomly
picked among all the constructions. \\
We have to take this strong hypothesis because the OpenStreetMap dataset lacks
information about the building use and height in most entries.

These two points can be accepted in this work as the end goal is to study how
the access network of a city like Aachen behaves, not to replicate it in perfect
detail.

** Network design
:PROPERTIES:
:CUSTOM_ID: methodology-network_design
:END:

#+BEGIN_SRC org :exports none
  Using ILP to build the network

  - network requirements
    + ISP recommendations
    + best practices (CISCO, ...)
  - actual solution we are trying to find
    + optimal DSLAM positioning
    + optimal + heuristic check for routers and mainframe positions (restrict root nodes?)
  - why ILP? how does it work? (brief)
  - problem definition
    + idea for the model: Steiner tree + other constraints (cite requirements)
    + actual equations
  - problem complexity: number of variables, constraints (in theory)
#+END_SRC

This information is then condensed in an abstract graph $G=(V, \,E)$, with
streets as edges and road crossings as vertices. The former were given
corresponding lane length, while the latter were assigned the supposed number of
people living in the surrounding area.

More specifically, each node $i \in V$ is assigned a number of users $u_i$ to
serve and, since that they represent a physical line, edges in $E$ are given a
length value $l_e$: both these parameters will be used later to evaluate the
access network cost.

In this chapter we will exploit this information to find the optimal network
configuration, given some assumptions and requirements derived from best
practices in access network design. cite:CiscoWAN

*** Topology considerations
As depicted in autoref:fig:network_tree we suppose our access network to be made
of layer-2 type switches and to be logically shaped as a tree. This is indeed
common practice in such access networks, where more complex and elaborate
topologies are too expensive and offer no substantial benefit. cite:CiscoWAN

In this configuration the path from users to the provider mainframe is fixed and
must cross two kinds of intermediate nodes, a [[acp:dslam][DSLAM]] and a router.

#+BEGIN_SRC plantuml :file ../figures/network_tree.eps :noweb yes
  <<plantuml_skin>>
  skinparam nodesep 10

  queue Backbone as b

  rectangle Mainframe as m #ff9b9b

  rectangle Router as r1 #ffda9b
  rectangle Router as r2 #ffda9b
  rectangle Router as r3 #ffda9b

  rectangle DSLAM as d1 #f6ff9b
  rectangle DSLAM as d2 #f6ff9b
  rectangle DSLAM as d3 #f6ff9b
  rectangle DSLAM as d4 #f6ff9b
  rectangle DSLAM as d5 #f6ff9b
  rectangle DSLAM as d6 #f6ff9b

  interface " " as c1
  interface " " as c2
  interface " " as c3
  interface " " as c4
  interface " " as c5
  interface " " as c6
  interface " " as c7
  interface " " as c8
  interface " " as c9
  interface " " as c10
  interface " " as c11
  interface " " as c12
  interface " " as c13
  interface " " as c14
  interface " " as c15
  interface " " as c16
  interface " " as c17
  interface " " as c18

  b -- m

  m -- r1
  m -- r2
  m -- r3

  r1 -- d1
  r1 -- d2
  r2 -- d3
  r2 -- d4
  r3 -- d5
  r3 -- d6

  d1 -- c1
  d1 -- c2
  d1 -- c3
  d2 -- c4
  d2 -- c5
  d2 -- c6
  d3 -- c7
  d3 -- c8
  d3 -- c9
  d4 -- c10
  d4 -- c11
  d4 -- c12
  d5 -- c13
  d5 -- c14
  d5 -- c15
  d6 -- c16
  d6 -- c17
  d6 -- c18

  r1 -[hidden] r2
  r2 -[hidden] r3

  d1 -[hidden] d2
  d2 -[hidden] d3
  d3 -[hidden] d4
  d4 -[hidden] d5
  d5 -[hidden] d6

  c1 -[hidden] c2
  c2 -[hidden] c3
  c3 -[hidden] c4
  c4 -[hidden] c5
  c5 -[hidden] c6
  c6 -[hidden] c7
  c7 -[hidden] c8
  c8 -[hidden] c9
  c9 -[hidden] c10
  c10 -[hidden] c11
  c11 -[hidden] c12
  c12 -[hidden] c13
  c13 -[hidden] c14
  c14 -[hidden] c15
  c15 -[hidden] c16
  c16 -[hidden] c17
  c17 -[hidden] c18
#+END_SRC

#+LABEL: fig:network_tree
#+CAPTION: A layered tree access network connects users (circles) to the Internet backbone
#+ATTR_LATEX: :height 3.5in
#+RESULTS[8ea501892da9a680d09dae6c57f8da0bec56e358]:
[[file:../figures/network_tree.eps]]

From a technological point of view the network is considered to be relatively
modern, since the infrastructure has been renewed on the past years in
conjuction with works on main city roads.

That is the reason why we suppose all main links to be fiber optic running
state-of-the-art VDSL/VDSL2. The minor fraction of legacy ADSL and copper-cable
users can be well approximated as VDSL connections at the same distance, in
terms of bandwidth and other network metrics.

In order to guarantee a suitable [[ac:qos][QoS]], all connected network components have to
be close enough to each other: this is taken into account though a maximum
distance parameter $d_M$.

Finally, each switch is allowed to serve a limited number $n_M$ of lower level
nodes, given by the number of physical ports of the device.

*** Solution approach
:PROPERTIES:
:CUSTOM_ID: solution-approach
:END:

In smaller contexts, a manually design of the network suffices to meet all the
technological constraints while being reasonably cheap. This is not our case,
since the set of possible topologies is far too vast for a manual evaluation: a
programmatic strategy is then necessary to proceed.

Problems on graphs similar to the one we face are often solved using either [[ac:ilp][ILP]]
or an heuristic approach. cite:Koch1998,Rehfeldt2015,Diane1993,Leitner2014 \\
The former is a powerful mathematical tool that finds the best possible solution
to the problem, but it is very demanding with respect to computational resources
and time. \\
The latter instead does not strive to give the optimum, but can hopefully
achieve decent results in a more reasonable amount of time.

A mathematical model can be written to describe the multi-layered system as a
whole, but its complexity would have made it impossible to handle by any solver,
both in terms of number of variables and constraints.

To overcome this issue a different way of designing the topology has to be
devised. Instead of positioning all the nodes at once, the proposed algorithm
would place the leaves of the tree, meaning the [[ac:dslam][DSLAM]]s, first and then move up
to the higher-level elements. \\
This is closer to what is done in practice, as each step is examined and
evaluated according to criteria, such as soundness and future-proofing of the
infrastructure, that are difficult to explain to the solver.

The network topology moves then from the one in [[autoref:fig:network_tree]] to the
simplified setting of autoref:fig:network_tree_simplified.

#+BEGIN_SRC plantuml :file ../figures/network_tree_simplified.eps :noweb yes
  <<plantuml_skin>>
  skinparam nodesep 10

  queue Backbone as b

  rectangle Mainframe as r #ff9b9b

  rectangle Head as d1 #f6ff9b
  rectangle Head as d2 #f6ff9b
  rectangle Head as d3 #f6ff9b
  rectangle Head as d4 #f6ff9b
  rectangle Head as d5 #f6ff9b
  rectangle Head as d6 #f6ff9b

  interface " " as c1
  interface " " as c2
  interface " " as c3
  interface " " as c4
  interface " " as c5
  interface " " as c6
  interface " " as c7
  interface " " as c8
  interface " " as c9
  interface " " as c10
  interface " " as c11
  interface " " as c12
  interface " " as c13
  interface " " as c14
  interface " " as c15
  interface " " as c16
  interface " " as c17
  interface " " as c18

  b -- r

  r -[dashed]- d1
  r -[dashed]- d2
  r -[dashed]- d3
  r -[dashed]- d4
  r -[dashed]- d5
  r -[dashed]- d6

  d1 -- c1
  d1 -- c2
  d1 -- c3
  d2 -- c4
  d2 -- c5
  d2 -- c6
  d3 -- c7
  d3 -- c8
  d3 -- c9
  d4 -- c10
  d4 -- c11
  d4 -- c12
  d5 -- c13
  d5 -- c14
  d5 -- c15
  d6 -- c16
  d6 -- c17
  d6 -- c18

  d1 -[hidden] d2
  d2 -[hidden] d3
  d3 -[hidden] d4
  d4 -[hidden] d5
  d5 -[hidden] d6

  c1 -[hidden] c2
  c2 -[hidden] c3
  c3 -[hidden] c4
  c4 -[hidden] c5
  c5 -[hidden] c6
  c6 -[hidden] c7
  c7 -[hidden] c8
  c8 -[hidden] c9
  c9 -[hidden] c10
  c10 -[hidden] c11
  c11 -[hidden] c12
  c12 -[hidden] c13
  c13 -[hidden] c14
  c14 -[hidden] c15
  c15 -[hidden] c16
  c16 -[hidden] c17
  c17 -[hidden] c18
#+END_SRC

#+LABEL: fig:network_tree_simplified
#+CAPTION: Each /head/ aggregates the traffic of all nodes in its /cluster/.
#+ATTR_LATEX: :height 2.5in
#+RESULTS[5085dfc30f26ccf8321faf35dc8ee483110cc158]:
[[file:../figures/network_tree_simplified.eps]]

As apparent in the diagram the solver must now take into consideration the cost
of the nodes that have been omitted from the tree. This is accounted as a lump
sum for the connection of each network switch, called from now on cluster
/head/, to the mainframe both in terms of cables and intermediate nodes.

Both the exact and approximate approach that will be proposed in this thesis
will build the access network in this fashion, starting from the periphery and
moving towards the core of the network.

All relevant parameters have been collected in [[autoref:quantities_constraints]] and
will be taken for granted from now on.

#+NAME: quantities_constraints
#+CAPTION: Problem parameters, divided in topology specific ones, technological limits and costs.
#+ATTR_LATEX: :align cl
| Variable        | Description                                                   |
|-----------------+---------------------------------------------------------------|
| $G = (V, \, E)$ | Graph describing the city topology                            |
| $T \subseteq V$ | Set of terminal nodes                                         |
| $l_e = l_{ij}$  | Length of edge $e = (i,\,j) \in E$                            |
| $u_i$           | Number of users at terminal $i \in T$                         |
|-----------------+---------------------------------------------------------------|
| $d_M$           | Maximum distance from a terminal and its root                 |
| $n_M$           | Maximum number of terminals per tree                          |
|-----------------+---------------------------------------------------------------|
| $c_r$           | Cost of a single subtree root node, plus mainframe connection |
| $c_f$           | Cost of a fiber optic cable per meter                         |
| $c_e$           | Cost of roadwork excavation per meter                         |

*** ILP formulation
In order to express the optimization problem in a convenient way, we arrange our
data as follows.

A direct graph $G^\prime = (V \cup \{r\},\, A)$ is induced on top of the $G$, where
the set of arcs $A$ is defined as follows.

#+NAME: induction_G
\begin{equation}
  A = \left\{ (i,\,j),\, (j,\,i) ~~ \forall \{i, j\} \in E \right\} \cup
  \left\{ (r,\,j) ~ \forall j \in V \right\}
\end{equation}

In autoref:induction_G each undirected edge in $E$ is doubled with the two
corresponding directed arcs; then an artificial node $r$ is added to the
vertices set and connected to each of the nodes in $V$.

Each arc $(i,\,j) \in A$ is assigned a length $l_{ij}$, in meters, given by the
geographical distance between its endpoints. Artificial arcs $(r,\,j)$ do not
correspond to physical connections and so $l_{rj} = 0 ~~ \forall j \in V$.

With this setup our network access configuration will simply be a direct tree, or
/arborescence/, with root in $r$, as depicted in autoref:fig:tree_network.

#+BEGIN_SRC plantuml :file ../figures/ilp_graph_reduced.eps :noweb yes
  <<plantuml_skin>>
  skinparam nodesep 10

  skinparam ArrowFontSize 25
  skinparam UsecaseFontSize 25
  hide empty description

  usecase "r" as r #ff9b9b

  usecase " " as d1 #f6ff9b
  usecase " " as d2 #f6ff9b
  usecase " " as d3 #f6ff9b
  usecase " " as d4 #f6ff9b
  usecase " " as d5 #f6ff9b
  usecase "i" as d6 #f6ff9b

  usecase " " as c1
  usecase " " as c2
  usecase " " as c3
  usecase " " as c4
  usecase " " as c5
  usecase " " as c6
  usecase " " as c7
  usecase " " as c8
  usecase " " as c9
  usecase " " as c10
  usecase " " as c11
  usecase " " as c12
  usecase " " as c13
  usecase " " as c14
  usecase " " as c15
  usecase " " as c16
  usecase " " as c17
  usecase " " as c18

  usecase " " as n1
  usecase " " as n2
  usecase " " as n3
  usecase " " as n4
  usecase " " as n5
  usecase " " as n6
  usecase " " as n7
  usecase " " as n8
  usecase " " as n9
  usecase " " as n10
  usecase " " as n11
  usecase " " as n12
  usecase " " as n13
  usecase " " as n14
  usecase " " as n15
  usecase " " as n16
  usecase " " as n17
  usecase " " as n18
  usecase " " as n19
  usecase " " as n20
  usecase " " as n21
  usecase " " as n22
  usecase " " as n23
  usecase " " as n24

  r -[#ff5050]->> d1
  r -[#ff5050]->> d2
  r -[#ff5050]->> d3
  r -[#ff5050]->> d4
  r -[#ff5050]->> d5
  r -[#ff5050]->> d6 : "(r, i)"

  d1 -->> c1
  d1 -->> c2
  d1 -->> c3
  d2 -->> c4
  d2 -->> c5
  d2 -->> c6
  d3 -->> c7
  d3 -->> c8
  d3 -->> c9
  d4 -->> c10
  d4 -->> c11
  d4 -->> c12
  d5 -->> c13
  d5 -->> c14
  d5 -->> c15
  d6 -->> c16
  d6 -->> c17
  d6 -->> c18

  c1  -->> n1
  c1  -->> n2
  c2  -->> n3
  c3  -->> n4
  c4  -->> n5
  c5  -->> n6
  c5  -->> n7
  c6  -->> n8
  c7  -->> n9
  c8 -->> n10
  c8 -->> n11
  c8 -->> n12
  c9 -->> n13
  c9 -->> n14
  c10 -->> n15
  c11 -->> n16
  c11 -->> n17
  c12 -->> n18
  c14 -->> n19
  c15 -->> n20
  c15 -->> n21
  c16 -->> n22
  c18 -->> n23
  c18 -->> n24

  d1 -[hidden] d2
  d2 -[hidden] d3
  d3 -[hidden] d4
  d4 -[hidden] d5
  d5 -[hidden] d6

  c1 -[hidden] c2
  c2 -[hidden] c3
  c3 -[hidden] c4
  c4 -[hidden] c5
  c5 -[hidden] c6
  c6 -[hidden] c7
  c7 -[hidden] c8
  c8 -[hidden] c9
  c9 -[hidden] c10
  c10 -[hidden] c11
  c11 -[hidden] c12
  c12 -[hidden] c13
  c13 -[hidden] c14
  c14 -[hidden] c15
  c15 -[hidden] c16
  c16 -[hidden] c17
  c17 -[hidden] c18
#+END_SRC

#+LABEL: fig:tree_network
#+CAPTION: In the final solution, additional arcs $(r,\, i)$ connect artifical node $r$ to all the roots, making the whole structure an arborescence, instead of a forest.
#+ATTR_LATEX: :width \linewidth
#+RESULTS[73e203a14ca9323ed263eab6c671feafb662aded]:
[[file:../figures/ilp_graph_reduced.eps]]

Because of the system requirements we also have to keep track of the distance
$d_i$ of each node $i \in V \cup \{r\}$ from its head and the number of users $n_e$ served
by each link in $A$, ensuring they do not exceed their limits.

Given this setup, our optimization problem can be written as follows:

\begin{align}
  \min_{ \stackrel{\{x_e\}_{e \in E}}{\{u_t\}_{t \in T}}}
  & \left( \sum_{t \in T} d_t \, u_t \right) \, c_c
    + \left( \sum_{e \in E} x_e \, l_e \right) \, c_e
    + \left( \sum_{e \in \delta^+(r)} x_e \right) \, c_r
    \label{eq:obj_function} \\[0.8em]
  \text{subject to ~~}
  & \sum_{e \in \delta^-(j)} x_e ~
    \begin{dcases}
      = 0 & j = r \\
      = 1 & j \in T \\
      \le 1 & j \in V \setminus T
    \end{dcases} \label{eq:single_arc_in} \\[0.5em]%
    % & \forall j \in V, \sum_{e \in \delta^+(j)} x_e
    % \le \left( \sum_{e \in \delta^-(j)} x_e \right)
    % \, \max_{v \in V} \left| \delta^+(v) \right|
    % \label{eq:nodes_reachability} \\[0.5em]
  & \sum_{e \in \delta^+(r)} x_e \ge 1
    \label{eq:r_active} \\[0.5em]
  & \forall j \in V \cup \{r\}, ~ d_j \le \left( \sum_{e \in \delta^-(j)} x_e \right) d_M
    \label{eq:distance_upper_limit} \\[0.2em]
  & \forall (i,\,j) \in A ~
    \begin{dcases}
      ~ d_j - d_i \ge l_{ij} ~ x_{ij} - d_M \, (1 - x_{ij}) \\[0.2em]
      ~ d_j - d_i \le l_{ij} ~ x_{ij} + d_M \, (1 - x_{ij})
    \end{dcases}
  \label{eq:distance_progression} \\[1.5em]
  & \forall e \in A,\, n_e \le x_e \, n_M
    \label{eq:n_terminals_upper_limit} \\
  & \sum_{e \in \delta^-(j)} n_e - \sum_{e \in \delta^+(j)} n_e =
    \begin{dcases}
      ~ p_j & j \in T \\[0.2em]
      ~ 0 & j \in V \setminus T
    \end{dcases} \label{eq:n_flow_balance} \\[0.5em]
  & \sum_{e \in \delta^+(r)} n_e = \sum_{i \in T} u_i
    \label{eq:root_sink} \\[0.8em]
  & \forall e \in A, \, x_e \in \{0, \, 1\}, \, n_e \in \mathbb{N} \cup \{0\}
    \label{eq:var_domain_1} \\[0.5em]
  & \forall j \in V \cup \{r\}, \, d_j \ge 0
    \label{eq:var_domain_2}
\end{align}

To clear the notation, we have defined functions $\delta^+, \, \delta^-: V \rightarrow
\mathbb{P}(A)$ associating each node with the out-going and in-going edges
respectively.

\begin{equation}
  \begin{split}
    \delta^+(j) &= \left\{ (j,\,k) \in A \right\} \\
    \delta^-(j) &= \left\{ (i,\,j) \in A \right\} \\
  \end{split}
\end{equation}

The problem is set to minimize the objective function autoref:eq:obj_function
that sums up the cost of optical fiber lines, roadworks and the total price of
/head/ switching units.

The first constraint autoref:eq:single_arc_in forces the terminals to be connected
to our network and sets the number of in-going arcs to be at most one, which is a
necessary condition for the network to be a directed tree.

As the leaves are set to be part of the network, $r$ has to be as well by
autoref:eq:r_active. It will then be the root node of the resulting tree, as by
construction of $G^\prime$ node $r$ has no in-going arcs.

The next equations deal with the variables $d_j$, distance from the tree root.
First, in autoref:eq:distance_upper_limit this quantity is limited by $d_M$ if
the node is reached by the network, otherwise it is set to zero. \\
On the other hand autoref:eq:distance_progression guarantees the consistency of
this metric between two connected nodes, forcing target node distance to be the
source one plus the link length. \\
Implicitly the latter prevents the resulting network to have loops, necessary
for our solution to be a proper arborescence.

The last needed metric for limiting the possible solutions is the number of
users each link can handle, $n_M$. This upper limit for $n_e$ is set in
autoref:eq:n_terminals_upper_limit such that it has to hold only for active
edges, and then the count of the users from leaves to each sub-root is performed
in autoref:eq:n_flow_balance, which has the same form as a flow-conservation
clause. \\
All such flows must converge towards the root $r$ for autoref:eq:root_sink: this
forces the network to be connected, finally giving it the wanted shape.

Variable domains are eventually specified in autoref:eq:var_domain_1 and
autoref:eq:var_domain_2.

\bigbreak

Overall, the model requires $|V| + 1 + 4 \, |E|$ variables and $3\, |V| +
2\,|T| + 4 \, |E| + 1$ constraints, both of which are $O(|V|)$ for sparse graphs like the one we are working on.

*** Heuristic algorithm
:PROPERTIES:
:CUSTOM_ID: methodology-heuristic
:END:

The mathematical problem described in the previous section can be effectively
solved only for small instances, i.e. sparse graphs with up to one hundred
nodes. \\
In fact, when tested on our specific case with tens of thousands of nodes and
edges, the program could not output the solution within a reasonable amount of
time and resources.

An heuristic approach had to be devised: for the peculiarities of the problem it
is indeed suitable a \emph{greedy} approach, inspired by hierarchical clustering.

The basic idea is to progressively join single nodes of the graph in bigger and
bigger /clusters/ until the total cost decreases: once a merge results in a more
expensive network, the algorithm stops. \\
Such merges are allowed whenever the mentioned [[ac:qos][QoS]] constraints are met and
adjacent subsets are preferred. To be precise, distance between each couple of
groups is defined as the distance of the closest elements: this is done to
privilege more cohesive and compact pairs.

This procedure is repeated until all possible choices have been considered or
the next merge increases the cost of the network.

Pseudo-code is available in [[autoref:lst:alg:heuristic]].

\begin{bigalgorithm}
  \label{lst:alg:heuristic}
  \begin{algorithmic}
    \caption{Heuristic solver}
    % \State /* \quad \textsc{init} phase \quad */
    \State $C=\emptyset$
    \State $\forall\, t \in T$ add singleton $\{t\}$ to $C$
    \State mark all couples $C_i, C_j \in C^2$ as mergeable
    \State cost = \Call{objective\_function}{$C$}
    \State
    \State stop = False
    \Repeat
    % \State /* \quad \textsc{iteration} phase \quad */
    \State pick $C_i$ and $C_j$ the two closest clusters in $C$
    \State $d_{ij}$ = diameter of cluster $C_i \cup C_j$
    \State $n_{ij}$ = number of users inside $C_i \cup C_j$
    \State
    \If {$d_{ij} < 2 \, d_M$ and $n_{ij} < n_M$}
    \State $C^\prime = \{C_1, \ldots, C_i \cup C_j, \ldots \}$
    \State current\_cost = \Call{objective\_function}{$C^\prime$}
    \State
    % \State /* \quad \textsc{performance} stop condition \quad */
    \If {current\_cost > cost}
    \State stop = True
    \Else
    \State $C = C^\prime$
    \EndIf
    \State merge $C_i$ and $C_j$
    \Else
    \State mark the couple $C_i$ and $C_j$ as unmergeable
    \EndIf
    \State
    % \State /* \quad \textsc{exhaustion} stop condition \quad */
    \If {$\nexists \, C_i, C_j \in C^2$ mergeable}
    \State stop = True
    \EndIf
    \Until { stop = False }
    \State \Return $C$
  \end{algorithmic}
\end{bigalgorithm}

The cost of each sub-network is not evaluated on the best possible
configuration, but instead goes for a sub-optimal one. \\
This is required for the algorithm to be feasible, as the Steiner-tree-like
problem that it has to be solved in order to connect all cluster nodes to a
common sub-root is yet again too complex.

As can be seen in [[autoref:lst:alg:heuristic_obj]], each node close enough to the
cluster is evaluated as a candidate root of the corresponding spanning tree. The
network is then simply built joining the minimum paths between the best of those
and the terminals of the set.

\begin{bigalgorithm}
  \label{lst:alg:heuristic_obj}
  \begin{algorithmic}
    \caption{Approximated objective function}
    \Function{objective\_function}{$C$}
    \State total\_cost = 0
    \ForAll{$c \in C$}
    \State best\_cost = $+\infty$
    \ForAll{$v \in V$ close to $c$}
    \State $T_v = \bigcup_{t \in C} \text{minimum path from } v \text{ to } t$

    \State $\text{cost}_v = \text{cable cost of } T_v + \text{excavation cost of } T_v$
    \If {$\text{cost}_v < \text{best\_cost}$ }
    \State $\text{best\_cost} = \text{cost}_v$
    \EndIf
    \EndFor
    \State total\_cost += best\_cost
    \EndFor
    \State \Return total\_cost
    \EndFunction
  \end{algorithmic}
\end{bigalgorithm}

For now all these approximations are mandatory for the algorithm to be fast
enough to deal with our case of study, but in [[autoref:results-network_design]]
they will prove to be good ones, i.e. to be close to the theoretical optimum.

** Network optimization
:PROPERTIES:
:CUSTOM_ID: methodology-network_optimization
:END:

#+BEGIN_SRC org :exports none
  - network structure
    - flow control only viable tuning of the logical network
    - components in deeper focus
  - training approach
    - definition of objective function <~ game theory applied
    - waterfilling
    - heuristic waterfilling-inspired approach
#+END_SRC

Previous optimization steps returned a plausible topology for Aachen city access
network.

As mentioned earlier, the next step we take is to optimize it, in order to
assess weather the more flexible framework provided by [[ac:sdn][SDN]] can benefit the
overall performance.

*** Network structure
As presented in autoref:methodology-network_design, the obtained network
topology is organized in a hierarchical tree of switches, whose task is to merge
all uplink communications towards the mainframe and split the downlink ones
among the various destinations.

This structure resembles what was previously described in
autoref:fig:network_tree, and is further detailed in
autoref:fig:simulator_downlink and autoref:fig:simulator_uplink.

As shown in these diagrams, each outgoing flow passes through a controller,
whose task is to govern and limit the data rate before it enters the
transmitting interface, labeled as ``NIC''. All these units can be coordinated
by the central administrator in order to give or revoke priority from a given
source.

Since in our setting all data flows are supposed to be [[ac:cbr][CBR]], deciding bandwidth
allocation is the definitive tool to provide users the best service.

#+NAME: fig:simulator_downlink
#+BEGIN_SRC plantuml :file ../figures/simulator_downlink.eps :noweb yes
  skinparam nodesep 10
  skinparam ranksep 30
  <<plantuml_skin>>
  left to right direction

  node "DSLAM" as dslam1
  node "DSLAM" as dslam2
  node "DSLAM" as dslam3

  node ROUTER {
  queue "CTR" as ROUTER_ctr1 #f6ff9b
  queue "CTR" as ROUTER_ctr2 #f6ff9b
  queue "CTR" as ROUTER_ctr3 #f6ff9b
  queue "NIC" as ROUTER_queue
  queue "NIC" as interface1
  queue "NIC" as interface2
  queue "NIC" as interface3
  }

  database "Server" as server1
  database "Server" as server2

  node "Mainframe" as mf
  dslam1 <-- interface1
  dslam2 <-- interface2
  dslam3 <-- interface3

  interface1 <-- ROUTER_ctr1
  interface2 <-- ROUTER_ctr2
  interface3 <-- ROUTER_ctr3

  ROUTER_ctr1 <-- ROUTER_queue
  ROUTER_ctr2 <-- ROUTER_queue
  ROUTER_ctr3 <-- ROUTER_queue

  ROUTER_queue <-- mf

  cloud "Public\nInternet" as internet
  mf <-- internet

  internet <-- server1
  internet <-- server2
#+END_SRC

# #+ATTR_LATEX: :width 8cm
#+CAPTION: Logical node structure for downlink traffic.
#+LABEL: fig:simulator_downlink
#+RESULTS[b9c70fa3ebb841fc5ece1117e8000300baed9947]: fig:simulator_downlink
[[file:../figures/simulator_downlink.eps]]

#+NAME: fig:simulator_uplink
#+BEGIN_SRC plantuml :file ../figures/simulator_uplink.eps :noweb yes
  skinparam nodesep 10
  skinparam ranksep 30
  <<plantuml_skin>>
  left to right direction

  node "DSLAM" as dslam1
  node "DSLAM" as dslam2
  node "DSLAM" as dslam3

  node ROUTER {
  queue "CTR" as ROUTER_ctr #f6ff9b
  queue "NIC" as ROUTER_queue
  queue "NIC" as interface1
  queue "NIC" as interface2
  queue "NIC" as interface3
  }

  database "Server" as server1
  database "Server" as server2

  node "Mainframe" as mf
  dslam1 --> interface1
  dslam2 --> interface2
  dslam3 --> interface3

  interface1 --> ROUTER_ctr
  interface2 --> ROUTER_ctr
  interface3 --> ROUTER_ctr

  ROUTER_ctr --> ROUTER_queue

  ROUTER_queue --> mf

  cloud "Public\nInternet" as internet
  mf --> internet

  internet --> server1
  internet --> server2
#+END_SRC

# #+ATTR_LATEX: :width 8cm
#+CAPTION: Logical node structure for uplink traffic.
#+LABEL: fig:simulator_uplink
#+RESULTS[760c84bff898e8caa3d4fa8fdd17e68e456dc42c]: fig:simulator_uplink
[[file:../figures/simulator_uplink.eps]]

*** Quality of Experience
:PROPERTIES:
:CUSTOM_ID: methodology-qoe
:END:

In order to improve the network, first we have to define what \emph{improvement}
means. We decided to maximize user [[ac:qoe][QoE]], defined as a number in $[0,\,1]$,
ranging from unusable to perfect link. Each user $i$ is then given a
\emph{utility function}, mapping available bandwidth $\rho_i$ to perceived
quality.

The functions employed in this thesis were obtained, by multiple research
groups, collecting user opinion of the service with different available
bandwidth. cite:Georgopoulos2013,Schatz2011 These studies suggest a precise link
between [[ac:qoe][QoE]] and the network metric, described by autoref:eq:utility_general.

\begin{equation} \label{eq:utility_general}
u(\rho) = a \, \rho^b + 1
\end{equation}

where $a$ and $b$ are instead application specific coefficients and $\rho$ is
the assigned bandwidth.

\smallskip

More specifically, our network will consider two different use-cases:
traditional web-browsing and video streaming. Videos will either be Low
Definition (360p), Medium Definition (720p), or High Definition (1080p).
Following \emph{Google Video Quality Report}, each one of those will be
experienced by 5%, 10% and 85% of the users respectively.
cite:GoogleVideoQualityReport

#+NAME: video_quality_report
#+BEGIN_SRC python :noweb yes :exports results :results file output
  <<python_preamble>>

  labels = 'Low Definition', 'Medium Definition', 'High Definition'
  sizes = (5, 10, 85)
  explode = (0.1, 0.1, 0)

  fig = plt.figure(frameon=False, figsize=(4, 2))
  ax = fig.gca()
  ax.pie(sizes, explode=(0.1, 0.1, 0.1), labels=labels, autopct='%1.0f%%', startangle=0)
  ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

  out_path = "../figures/streamers_profiles.pdf"
  plt.tight_layout(pad=0)
  plt.savefig(out_path)

  # plt.show()

  print(out_path, end='')
#+END_SRC

#+CAPTION: Distribution of video quality among video streaming users. cite:GoogleVideoQualityReport
#+ATTR_LATEX: :height 2in
#+LABEL: fig:video_quality_report
#+RESULTS[bec44a5a0c483a75d987ba16e85eac166702ddac]: video_quality_report
[[file:../figures/streamers_profiles.pdf]]

Parameters $a$ and $b$ are then tuned in order to properly link user perception of
the different services to available resources, as shown in autoref:fig:utilities.

#+NAME: utilities
#+BEGIN_SRC R :exports results :results file value :noweb yes
  <<R_preamble>>

  library(pracma)

  utility <- function(x, a, b) {
    return(a * `^`(x, b) + 1)
  }

  as <- c(-3.035, -4.850, -17.53, -14.98544276)
  bs  <- c(-.5061, -.6470, -1.048, -0.8780054)
  types  <- c('Streaming HD',
             'Streaming MD',
             'Streaming LD',
             'Web broswing')

  x <- logspace(2, 4, 100)

  data <- data.frame('type'=c(), 'Bandwidth'=c(), 'Utility profiles'=c())

  for (index in seq(from=1, to=length(as), by=1)) {
    current_data <- data.frame(
      'Utility profiles'=types[index],
      'Bandwidth'=x,
      'Utility'=utility(x, as[index], bs[index])
    )
    data <- rbind(data, current_data)
  }

  current <- ggplot(data, aes(x=Bandwidth, y=Utility, color=Utility.profiles)) +
    labs(x='Bandwidth [kbit/s]', color='Utility profiles') +
    scale_x_continuous(trans='log', breaks=c(100, 1000, 10000)) +
    geom_line() +
    my_theme

  ## print(current)

  out_path <- '../figures/utilities.pdf'
  ggsave(plot = current,
         filename = out_path,
         width = 5,
         height = 3,
         unit = 'in',
         dpi = 300,
         device = 'pdf')

  print(out_path)
#+END_SRC

#+CAPTION: Utilities connect available bandwidth to user satisfaction of the given service.
#+ATTR_LATEX: :height 3in
#+LABEL: fig:utilities
#+RESULTS[008700d760fd52c73f6e90e6e9a089c26a190499]: utilities
[[file:../figures/utilities.pdf]]

Observing the four trends, it can be seen that [[ac:hd][HD]], [[ac:md][MD]] and [[ac:ld][LD]] video streaming are
in decreasing order of bandwidth demand, as expected. Instead, traditional web
browsing puts itself between [[ac:md][MD]] and [[ac:ld][LD]].

# This position can be explained by the fact that the growing size of pages is
# not followed by an increasing expectation time by the user.

*** Fairness on resource allocation
In order to manage the network optimally, we need to reach an operation point
$\vec{\rho}$ that balances demands of all parties involved.

Traditionally, the \emph{proportional fairness} principle is applied when
handling different flows. According to this rule, each switching unit allocates
bandwidth in \emph{proportion} to user demand. This has proven to be a reliable
way to distribute network resources, but it does not take into account the
application-dependent service quality perception.

Each user tends to maximize this subjective metric, called \emph{utility}, when
asking for bandwidth, but doing so it harms the [[ac:qos][QoS]] of its fellows. The [[ac:isp][ISP]] has
then to act as an arbiter, allocating available resources in a fair way. The
optimal solution of this problem was proven to be the so-called
\emph{Nash arbitration scheme} of the \emph{game} played among these actors.
cite:Mazumdar1991

Such point is unique and pareto-optimal, and it can be found maximizing $f$,
product of all the utilities. This gives us a straightforward criterion in order
to rank all possible network configurations. In order to avoid issues related to
CPU floating point precision, $\log f(\vec{\rho})$ is computed instead in simulations.

\begin{equation}
  f(\vec{\rho}) = \prod_i u_i(\rho_i) \implies
  \argmax_{\vec{\rho}} ~ f(\vec{\rho}) = \argmax_{\vec{\rho}} ~ \sum_i \log u_i(\rho_i)
\end{equation}


In autoref:results-network_optimization we will then show if the traditional
approach to manage an access network is indeed fair or not, with respect to the
optimal strategy.

*** Flow balancing optimization
As anticipated in the previous section, the fair working point is identified as
the Nash arbitration scheme $\vec{\rho}$. More formally, it is solution of the
following mathematical problem.

\begin{align}
  \max_{\vec{\rho}} ~~ & \sum_{i=1}^n \log u_i(\rho_i) \\
  \text{given~~}
                 & \sum_{i=1}^n \rho_i \le \rho_{MAX} \\
                 & \forall j \in D, \,\sum_{i \in DSLAM_j} \rho_i \le \rho_{D,\,MAX}  \label{eq:dslam_max} \\
                 & \forall j \in R, \,\sum_{i \in ROUTER_j} \rho_i \le \rho_{R,\,MAX} \label{eq:router_max}
\end{align}

where $n$ is the total number of users and each [[ac:dslam][DSLAM]] and router, belonging to
sets $D$ and $R$, are assigned a subset of users $DSLAM_j$ and $ROUTER_j$ and a
maximum bandwidth $\rho_{D,\,MAX}$ and $\rho_{R,\,MAX}$, respectively.

This can be seen as a \emph{water-filling} problem, as a limited resource
$\rho_{MAX}$ has to be allocated maximising a concave objective function.

Unfortunately, however, our case is complicated by the two additional
constraints autoref:eq:dslam_max and autoref:eq:router_max: no algorithm is
currently known in literature able to solve the problem optimally. cite:Xing2018

A sub-optimal solution has then to be searched using an heuristic algorithm.
Given the monotonicity of the objective function, the following procedure is
employed.

\begin{bigalgorithm}
  \label{lst:alg:heuristic_flow}
  \begin{algorithmic}
    \caption{Flow optimization algorithm}
    \State Initialize all users, each with their utility function $u_i$
    \State Set $\rho_i = 0$, $\forall i=0, \ldots, n$
    \State Set stop\_condition = False
    \While{stop\_condition is False}
    \State Randomly choose $k$ among $\{1, ..., n\}$
    \State Perturb $\rho_k$ of a uniform random quantity in $[0,\, K]$
    \If{ $\rho_k$ does not respect constraints \autoref{eq:dslam_max} and \autoref{eq:router_max}}
    \State Revert perturbation on $k$
    \EndIf
    \If{ Objective function $f$ improvement is negligible }
    \State stop\_condition = True
    \EndIf
    \State Decrement $K$
    \EndWhile
    \State
    \Return $\vec{\rho}$
  \end{algorithmic}
\end{bigalgorithm}

A randomly picked bandwidth $\rho_i$ is iteratively incremented each round of a
uniform quantity in $[0,\, K]$: such perturbation is left unless any constraint
of the mathematical problem is violated. Once the operation is no more
beneficial, i.e. the increment is below a certain tolerance, the algorithm
stops.

The rationale behind this is akin to what happens in \emph{simulated annealing},
an heuristic search algorithm where perturbation of constantly decreasing size
are applied to the starting point in the hope of converging toward a good
solution. cite:Van1987

* Results
:PROPERTIES:
:CUSTOM_ID: results
:END:

This chapter follows the what was presented in [[autoref:methodology]] and shows
what can be obtained using those theoretical frameworks and tools.

** Geographical analysis
:PROPERTIES:
:CUSTOM_ID: results-geographical_analysis
:END:

#+BEGIN_SRC org :exports none
  + maps details (whatever): maps only here?
  + graph details
    - number of nodes (building & others)
    - number of edges
    - degree distribution
    - average node distance, population
    - ... anything basically ...
#+END_SRC

In order to obtain a decent map of the city, the two OpenStreetMap datasets
corresponding to buildings and streets of the entire state of North
Rein-Westphalia were downloaded, merged and cropped to remove anything outside
Aachen border. cite:OpenStreetMap

After those operations, the remaining 58,305 constructions and 9,759 roads were
paired with the population density information and used to draw the map in
autoref:results-geographical_analysis.

#+LABEL: fig:aachen_city_map
#+ATTR_LATEX: :height 4.5in
#+CAPTION: Summary of all Aachen district information we will employ: building, roads positions and population distribution.
[[file:../figures/aachen_citymap.png]]

As can be appreciated in the plot, the data is indeed quite accurate and
suitable for the conversion to an abstract graph with streets as edges and road
crossing as vertices. This procedure was performed using a dedicated library
that took care of all the quirks of OpenStreetMap measures[fn:2]. For example
polygons were considered in contact up to a certain tolerance distance and
everything outside the main connected component was pruned. Moreover all nodes
close to each other less than 20m were merged: this removed many useless details
and lowered the number of variables in the upcoming analysis.

Then each building was assigned residents, i.e. users of our access network,
uniformly with respect to the area population density and building surface, as
was explained in autoref:methodology-geographical_analysis.

To integrate customers information into the road graph, a first attempt was made
where a new vertex was created for every building, but the number of variables
turned out to be too high: it was then made the decision to assign the
inhabitants of the city to the closer road crossing. \\
All long roads were split and forced to be shorter than 200m: this way the
average displacement introduced via this approximation was reduced to just 50m,
tolerable for our purposes.

At the end of this pre-processing phase, the graph is made of 7,231 vertices and
9,272 edges and its complexity can be handled by our algorithms. \\
A visual representation is given in [[autoref:fig:aachen_city_graph]] that shows the
result of a small part of the city center, as tiny details could not be
otherwise discerned.

#+LABEL: fig:aachen_city_graph
#+ATTR_LATEX: :width 4in
#+CAPTION: City topology is converted into an abstract graph.
[[file:../figures/aachen_city_graph.png]]

[fn:2] See http://xiaming.me/posts/2016/12/18/process-gis-shapefile-with-graph-tools/

** Network design
:PROPERTIES:
:CUSTOM_ID: results-network_design
:END:

#+BEGIN_SRC org :exports none
  ILP results

  - CPLEX performance on the problem
    + computational time
    + number of branches
    + (ask Massimo in case)
  - show found solution for network
    + analyze performance of found solution (bandwidth, ...)
    + consideration on actual used heuristics
#+END_SRC

As was introduced in autoref:solution-approach, the design procedure is
performed starting from the edge of the network, first positioning [[acp:dslam][DSLAMs]],
then second level routers routers and finally the mainframe.

While the mathematical formulation is the same, each iteration requires
different values for the problem parameters. autoref:optimization_params
collects them all omitting the unnecessary ones, such as the fixed cost of the
single mainframe which is not relevant in our analysis.

It is worth mentioning that the cost per unit $c_r$ is split into two addends,
accounting for the physical device and its connection to the mainframe. The
price and the number of ports of the switching units match the most popular
items in the market and industry best practices. cite:CiscoWAN

#+NAME: optimization_params
#+CAPTION: Values for problem parameters in the first two iterations.
#+ATTR_LATEX: :align crrr
| Parameters     |          [[ac:dslam][DSLAM]] |         Routers | Mainframe |
|----------------+----------------+-----------------+-----------|
| $n_M$ [unit]   |             48 |             400 | -         |
| $d_M$ [m]      |          1,500 |               - | -         |
| $c_r$ [€/unit] | 1,000 + 30,000 | 15,000 + 85,000 | -         |
| $c_f$ [€/m]    |              3 |               3 | 3         |
| $c_e$ [€/m]    |            100 |             100 | 100       |

As anticipated in autoref:methodology-network_design the exact
solution to the placement optimization problems could not be obtained using [[ac:ilp][ILP]].
Even with a commercial software such as CPLEX cite:Cplex, in fact, computational
time and memory demand exceeded all resources available.

Although not conclusive, the solver provided useful insights on the valid
solution domain, specifically a lower bound for the objective function. These
limits are then compared against the configuration obtained via heuristic
algorithm, presented before in autoref:methodology-heuristic. \\
[[autoref:solution_table]] clearly shows that the heuristic result is indeed
remarkably close to the theoretical optimum and proves that the choices and
approximations made previously indeed captured all relevant features of the
problem.

#+NAME: solution_table
#+CAPTION: Cost of heuristic solution is compared to the theoretical limit given by [[ac:ilp][ILP]].
#+ATTR_LATEX: :align crr
| Problem                   | [[ac:dslam][DSLAM]] | 2nd level routers |
|---------------------------+-------+-------------------|
| Number of groups          | 1,125 |                72 |
| [[ac:ilp][ILP]] cost lower bound [M€] | 65.05 |             38.08 |
| Heuristic cost [M€]       | 67.73 |             39.38 |
| Heuristic gap             |    4% |                3% |
#+TBLFM: @5$2='(format "%d%% "(truncate (* 100 (/ (float (- @4$2 @3$2)) @3$2))));N::@5$3='(format "%d%% "(truncate (* 100 (/ (float (- @4$3 @3$3)) @3$3))));N

A visual representation of the obtained clusters, groups of devices connected to
the same switching unit, is given in [[autoref:fig:heuristic_result]] and in
autoref:fig:heuristic_mainframe. Again the map is cropped in order to scale at
the proper level of detail if needed.

\begin{figure}[htp]
  \captionsetup[subfigure]{skip=-15pt}
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{../figures/heuristic_DSLAM.png}
    \caption{DSLAM positioning}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{../figures/heuristic_2router.png}
    \caption{Second level routers positioning}
  \end{subfigure}
  \caption{The root nodes in red are hubs for terminals, black points.}
  \label{fig:heuristic_result}
\end{figure}

#+LABEL: fig:heuristic_mainframe
#+ATTR_LATEX: :height 4.5in
#+CAPTION: The mainframe, red dot, is located in an industrial complex and is connected to all second level routers.
[[file:../figures/heuristic_mainframe.png]]

** Network optimization
:PROPERTIES:
:CUSTOM_ID: results-network_optimization
:END:

As mentioned in autoref:methodology-network_optimization, we will analyze the
behaviour of our reference access network for different bandwidth demands and
application profiles.

In our simulations, former point is taken care of via $p_{active}$ parameter,
that is the probability a certain user is communicating or not. In order to
describe the latter factor, instead, applications are randomly split into video
streaming and web page browsing, according to probability $p_{streaming}$.

Two different allocation strategies are evaluated, namely \emph{traditional}
proportional fairness, and the more sophisticated Nash arbitration scheme,
computed via the \emph{heuristic} autoref:lst:alg:heuristic_flow.

With respect to global objective function $f(\rho)$, our proposed solution indeed
provides a more fair operation point than the traditional one, proving that
even an approximated solution outperforms what currently done in these kinds of
scenarios.

This gap can be easily spotted in autoref:fig:obj_vs_p_nothing0.1,
autoref:fig:obj_vs_p_nothing0.5 and autoref:fig:obj_vs_p_nothing0.9 , where
different values of $p_{active}$ and $p_{streaming}$ are tested and performance
is averaged across multiple simulation runs.

Moreover, this difference is more noticeable when offered traffic is higher,
i.e. when the situation is more difficult to handle from the point of view of
the administrator. This observation suggests that this novel approach can be
relevant from a practical point of view, as the infrastructure size and
complexity, and thus its cost, is often dictated by such worst-case scenario.

As a final remark, the proposed method performance is smoother, more
predictable, with respect to system parameters, and this again is a strong point
in the field, making the tool more trustworthy.

#+NAME: optimization_plotter
#+BEGIN_SRC R :exports none :noweb yes
  <<R_preamble>>

  traditional <- read.csv("../data/optimization/traditional.csv", header = TRUE)
  traditional$type <- "Heuristic"

  heuristic <- read.csv("../data/optimization/heuristic.csv", header = TRUE)
  heuristic$type <- "Traditional"

  dataset <- rbind(traditional, heuristic)

  summary <- group_by(dataset, p_nothing, p_streaming, type) %>% summarize(obj=mean(obj))
  summary$obj <- exp(summary$obj)

  summary <- summary[summary$p_streaming == p_streaming, ]
  padding <- (
    max(exp(summary$obj[summary$type == 'Traditional'])) -
    min(exp(summary$obj[summary$type == 'Traditional']))
  ) / 100

  current <- ggplot(summary, aes(x=1-p_nothing, y=obj, color=type)) +
      geom_line() +
      geom_errorbar(aes(ymin=obj - padding,
                        ymax=obj + padding)) +
      labs(x=TeX("$p_{active}$"),
           y="Objective function",
           color='Strategy') +
      scale_x_continuous(breaks=unique(summary$p_nothing), labels=round(unique(summary$p_nothing), 2)) +
      my_theme

  ## print(current)

  out_path <- sprintf('../figures/obj_vs_p_nothing_%f.pdf', p_streaming)
  ggsave(plot = current,
         filename = out_path,
         width = 5,
         height = 3,
         unit = 'in',
         dpi = 300,
         device = 'pdf')

  print(out_path)
#+END_SRC

#+NAME: obj_vs_p_nothing0.1
#+BEGIN_SRC R :exports results :results file value :noweb yes
p_streaming = 0.1

<<optimization_plotter>>
#+END_SRC

#+ATTR_LATEX: :width 5in :placement [t]
#+LABEL: fig:obj_vs_p_nothing0.1
#+CAPTION: Performance for $p_{streaming}$ = 0.1, with $95\%$ confidence intervals.
#+RESULTS[3a7e1f61e204039afb78c821dfd64ef09a0312f0]: obj_vs_p_nothing0.1
[[file:../figures/obj_vs_p_nothing_0.100000.pdf]]

#+NAME: obj_vs_p_nothing0.5
#+BEGIN_SRC R :exports results :results file value :noweb yes
p_streaming = 0.5

<<optimization_plotter>>
#+END_SRC

#+ATTR_LATEX: :width 5in :placement [t]
#+LABEL: fig:obj_vs_p_nothing0.5
#+CAPTION: Performance for $p_{streaming}$ = 0.5, with $95\%$ confidence intervals.
#+RESULTS[aa1ca3384364a67258da6206e60f7b248dbc5b4d]: obj_vs_p_nothing0.5
[[file:../figures/obj_vs_p_nothing_0.500000.pdf]]

#+NAME: obj_vs_p_nothing0.9
#+BEGIN_SRC R :exports results :results file value :noweb yes
p_streaming = 0.9

<<optimization_plotter>>
#+END_SRC

#+ATTR_LATEX: :width 5in :placement [t]
#+LABEL: fig:obj_vs_p_nothing0.9
#+CAPTION: Performance for $p_{streaming}$ = 0.9, with $95\%$ confidence intervals.
#+RESULTS[37b1a7bea1c61e03ed83627db7713ea89816f50d]: obj_vs_p_nothing0.9
[[file:../figures/obj_vs_p_nothing_0.900000.pdf]]

\smallskip

Looking closer to the actual utility distribution among users, four reference
settings are shown in autoref:fig:utility_distribution0.1 and
autoref:fig:utility_distribution0.9, consisting of the extremes for $p_{active}$
and $p_{streaming}$.

#+NAME: utility_distribution
#+BEGIN_SRC R :exports none :noweb yes
  <<R_preamble>>

  facet_label <- labeller(p_active = function(value) {
    expression('$p_{active}$')
  })

  dataset <- read.csv("../data/optimization/utility_distribution.csv.gz", header = TRUE)

  dataset <- dataset[dataset$p_streaming == p_streaming, ]
  dataset <- dataset[dataset$p_nothing == 0.1 | dataset$p_nothing == 0.9, ]

  ## swap labels (opposite by mistake)
  library(plyr)
  dataset$type = revalue(dataset$type, c("Traditional"="Heuristic",
                                         "Heuristic"="Traditional"))

  dataset$p_active <- paste("p[active]*' = ", 1 - dataset$p_nothing, "'")

  current <- ggplot(dataset, aes(x=utility, fill=type)) +
    scale_y_continuous(trans='log1p', breaks=c(100, 1000, 10000, 25000, 60000)) +
    geom_histogram(bins=100, position="identity") +
    labs(x='Utility', y='Count', title='Utility distribution') +
    facet_grid(type ~ p_active, labeller=label_parsed) +
    my_theme +
    theme(legend.position='none',
          plot.title = element_text(hjust=0.5),
          panel.spacing = unit(0.8, "lines")) +
    scale_fill_brewer(palette="Set2", type='div')

  print(current)

  out_path <- sprintf('../figures/utility_distribution_%f.pdf', p_streaming)
  ggsave(plot = current,
         filename = out_path,
         width = 5,
         height = 5,
         unit = 'in',
         dpi = 300,
         device = 'pdf')

  print(out_path)
#+END_SRC

#+NAME: utility_distribution0.1
#+BEGIN_SRC R :exports results :results file value :noweb yes
  p_streaming = 0.1 ## 0.1000000 0.3666667 0.6333333 0.9000000

  <<utility_distribution>>
#+END_SRC

#+ATTR_LATEX: :width 5in :placement [t]
#+LABEL: fig:utility_distribution0.1
#+CAPTION: Utility distribution for $p_{streaming} = 0.1$.
#+RESULTS[3b480dabf54955f0e5e046cbddc4aff048ecb170]: utility_distribution0.1
[[file:../figures/utility_distribution_0.100000.pdf]]

#+NAME: utility_distribution0.9
#+BEGIN_SRC R :exports results :results file value :noweb yes
  p_streaming = 0.9 ## 0.1000000 0.3666667 0.6333333 0.9000000

  <<utility_distribution>>
#+END_SRC

#+ATTR_LATEX: :width 5in :placement [t]
#+LABEL: fig:utility_distribution0.9
#+CAPTION: Utility distribution for $p_{streaming} = 0.9$.
#+RESULTS[c28bccf955b649e4e15a2b0255b04d49b3665dd2]: utility_distribution0.9
[[file:../figures/utility_distribution_0.900000.pdf]]

While with a smaller offered traffic the solutions are similar, they differ at
the other side of the spectrum, where for example the traditional solution shows
spikes at very low values of utility that drag the objective function down.
Again, proposed approach is more desirable, as the solution is more ``stable''
than its counterpart.

Despite all these interesting features of this heuristic solution, it is
currently only a lower bound on the theoretical optimum, obtained solving the
mathematical problem exactly. Further progress can then be made in the search of
the best working point.

* Conclusions
:PROPERTIES:
:CUSTOM_ID: conclusion
:END:

- complete work, from bare geographical features to final network tuning
- the design approach is not limited to the specific context, but can be extended to any scenario
- interesting for broken emergency networks (Matilde)
- tuning shows hope for better (and significant) gains, but exact solution for the mathematical problem is needed
- using utilities is a better and more user-tailored approach than simple QoS metrics
- delay has to be considered in the equation (future progress)

\clearpage
bibliographystyle:plain
bibliography:biblio.bib

* COMMENT Local variables
# Local Variables:
# org-latex-tables-booktabs: t
# eval: (flyspell-mode)
# ispell-local-dictionary: "en"
# End:
