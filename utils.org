* Imports and defaults settings
  All imports should be gathered here.

  #+NAME: imports
  #+BEGIN_SRC python
    import csv
    import json
    import logging
    import math
    from math import sqrt
    from pathlib import Path

    import fiona
    import geopandas as gpd
    import matplotlib.pyplot as plt
    import networkx as nx
    import numpy as np
    import pandas as pd
    from matplotlib import rcParams
    from networkx.readwrite import json_graph
    from pyproj import Proj
    from s2g import ShapeGraph
    from shapely import wkt
    from shapely.geometry import LineString, Point, shape
    from shapely.geometry.polygon import Polygon
    from shapely.ops import cascaded_union, nearest_points

    logger = logging.getLogger('aachen_net.org')
    logger.setLevel(logging.INFO)
    logger.propagate = False

    formatter = logging.Formatter("%(asctime)s::%(levelname)s::%(module)s::%(message)s",
                                  "%Y-%m-%d %H:%M:%S")

    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    ch.setFormatter(formatter)
    logger.addHandler(ch)

    logger.info('import ok')
  #+END_SRC

  Default settings for ~matplotlib~.

  #+NAME: matplotlib_defaults
  #+BEGIN_SRC python
    font_spec = {
        'font.family':'sans-serif',
        'font.sans-serif':['Fira Sans'],
        'font.weight': 'regular'
    }
    rcParams.update(font_spec)

    logger.info('matplotlib ok')
  #+END_SRC

  #+NAME: imports_&_defaults
  #+BEGIN_SRC python :noweb yes
    <<imports>>
    <<matplotlib_defaults>>
  #+END_SRC

  Flatten ~org~ tables in lists of strings or single string.
  #+NAME: flatten
  #+BEGIN_SRC elisp :var listlike='()
    (let ((flattened-list (-flatten listlike)))
      (if (= 1 (length flattened-list))
          (car flattened-list)
        flattened-list))
  #+END_SRC

* Datasets reading routines
  Read district map and its projection details.

  #+NAME: districts
  #+BEGIN_SRC python
    district_map = gpd.read_file("data/aachen_net/aachen_district_map.shp")
    del district_map['FLÃ¤cHE'] # whole zero column

    logger.info('districts ok')
  #+END_SRC


  Read district map projection, used as default one across the computations.
  See [[https://gis.stackexchange.com/questions/17341/projection-pyproj-puzzle-and-understanding-srs-format][here]] for getting projection from ~prj~ file.

  #+NAME: projection
  #+BEGIN_SRC python
    prj_string_file = Path("data/aachen_net/aachen_district_map_prj.txt")
    if not prj_string_file.is_file():
        import osr # troublesome to install in cluster

        prj_content = open('data/aachen_net/aachen_district_map.prj', 'r').read()
        srs = osr.SpatialReference()
        srs.ImportFromWkt(prj_content)

        with open(str(prj_string_file), 'w') as f:
            f.write(srs.ExportToProj4())

    prj_string = open(str(prj_string_file), 'r').read()
    projection = Proj(prj_string)

    logger.info('projection ok')
  #+END_SRC

  Read population statistics for each district and join them to the district ~GeoDataFrame~.

  #+NAME: population
  #+BEGIN_SRC python
    district_population = pd.read_csv("data/aachen_net/20170630_population_density.csv")
    district_population.columns = ['STATBEZ', 'PERS']

    # join using index
    district_map.set_index('STATBEZ', inplace=True)
    district_population.set_index('STATBEZ', inplace=True)

    district_map['population'] = district_population['PERS']

    # compute area in km^2: I checked some in wikipedia to be sure
    district_map['area'] = district_map['geometry'].area / 10**6
    district_map['density'] = district_map['population'] / district_map['area']

    logger.info('population ok')
  #+END_SRC

  Read all roads and buildings that are either of ~None~ type or member of this group.
  #+NAME: valid_types
  | house            |
  | residential      |
  | apartments       |
  | industrial       |
  | school           |
  | farm             |
  | retail           |
  | allotment_house  |
  | warehouse        |
  | office           |
  | public           |
  | civic            |
  | hospital         |
  | university       |
  | manufacture      |
  | dormitory        |
  | community_centre |
  | hotel            |
  | bungalow         |
  | family_house     |
  | commercial       |

  #+NAME: roads
  #+BEGIN_SRC python
    roads_path = "data/aachen_net/aachen_roads.shp"
    roads_map = gpd.read_file(roads_path)
    roads_map.OSM_ID = pd.to_numeric(roads_map.OSM_ID)
    roads_map.crs = {'init': 'epsg:4326'}
    roads_map = roads_map.to_crs(projection.srs)

    logger.info('roads ok')
  #+END_SRC

  #+NAME: buildings
  #+BEGIN_SRC python
    buildings_path = "data/aachen_net/aachen_buildings.shp"
    buildings_map = gpd.read_file(buildings_path)
    buildings_map.OSM_ID = pd.to_numeric(buildings_map.OSM_ID)
    buildings_map.crs = {'init': 'epsg:4326'}
    buildings_map = buildings_map.to_crs(projection.srs)

    # set a custom label instead of None
    buildings_map.loc[buildings_map['TYPE'].isnull(), 'TYPE'] = "UNSET"

    # remove unwanted types, but keep UNSET ones
    buildings_map = buildings_map[buildings_map['TYPE'].isin(valid_types + ['UNSET'])]

    logger.info('buildings ok')
  #+END_SRC

  #+NAME: all_datasets
  #+BEGIN_SRC python :noweb yes :var valid_types=flatten(valid_types)
    <<imports_&_defaults>>
    <<projection>>
    <<districts>>
    <<population>>
    <<roads>>
    <<buildings>>
  #+END_SRC

* Cluster utilities
  Here comes handy job files for cluster execution, both for UniPD DEI and RWTH
  systems.
  Just replace the script with the one you want to run.

  #+BEGIN_SRC bash :tangle scripts/aachen_net_UniPD.job
    #!/bin/bash

    # create ouput files in job directory
    #$ -o /home/lovisott/master_thesis/out.txt
    #$ -e /home/lovisott/master_thesis/err.txt

    cd /home/lovisott/master_thesis/

    source venv/bin/activate
    GDAL_DATA=/home/lovisott/gdal python scripts/aachen_net/07_get_closest_roads.py
  #+END_SRC

  #+BEGIN_SRC bash :tangle scripts/aachen_net_RWTH.job
    #!/usr/bin/env zsh

    ### Job name
    #BSUB -J SERIALJOB

    ### File / path where STDOUT & STDERR will be written
    ###    %J is the job ID, %I is the array ID
    #BSUB -o SERIALJOB.%J.%I

    ### Request the time you need for execution in minutes
    ### The format for the parameter is: [hour:]minute,
    ### that means for 80 minutes you could also use this: 1:20
    #BSUB -W 100:23

    ### Request memory you need for your job in TOTAL in MB
    #BSUB -M 4096

    ### Change to the work directory
    cd /home/qt636081

    ### Execute your application
    python3 scripts/aachen_net/11_ILP.py
  #+END_SRC

* COMMENT Local variables
  # Local Variables:
  # eval: (add-hook 'before-save-hook (lambda () (indent-region (point-min) (point-max) nil)) t t)
  # End:
